自监督学习的方法可以大致分为以下几类：

#### **1. 生成式方法（Generative Methods）**

- **核心思想**：通过重构输入数据来学习特征。
    
- **典型任务**：
    
    - **自动编码器（Autoencoder）**：输入数据被编码为低维表示，再解码重建输入。损失函数为重建误差（如MSE）。
        
    - **变分自动编码器（VAE）**：在编码过程中引入概率分布，生成潜在变量。
        
    - **掩码重建（Masked Reconstruction）**：如BERT中的掩码语言模型（MLM），通过预测被掩码的单词或图像块。
        
- **适用场景**：图像、文本、时序数据等。
    

#### **2. 对比式方法（Contrastive Methods）**

- **核心思想**：通过对比正样本与负样本，学习区分相似与不相似的数据。
    
- **典型任务**：
    
    - **SimCLR/MoCo**：对同一数据的不同增强版本（正样本）进行相似性最大化，与其他数据（负样本）相似性最小化。
        
    - **三元组损失（Triplet Loss）**：拉近锚点与正样本的距离，推远锚点与负样本的距离。
        
- **适用场景**：图像分类、表示学习。
    

#### **3. 预测式方法（Predictive Methods）**

- **核心思想**：预测数据的某一部分或未来状态。
    
- **典型任务**：
    
    - **时间序列预测**：基于历史数据预测未来值。
        
    - **拼图重组（Jigsaw Puzzle）**：将图像分成小块，预测正确排列顺序。
        
    - **颜色化（Colorization）**：从灰度图像预测彩色通道。
        
- **适用场景**：视频分析、时间序列建模。
    

#### **4. 上下文预测（Context Prediction）**

- **核心思想**：利用数据中的上下文关系生成监督信号。
    
- **典型任务**：
    
    - **Skip-Gram（Word2Vec）**：通过中心词预测上下文词。
        
    - **邻域预测**：在图像中预测某一块的周围区域。
        
- **适用场景**：自然语言处理、图像分割。