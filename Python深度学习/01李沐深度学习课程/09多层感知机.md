# 1.单层感知机   f(wx + b)
这是最简单的神经网络
![|525](https://cleverbobo.github.io/2020/08/30/bp/3.png)
# 2. 多层感知机
至少一个隐藏层(softmax和单层感知机没有隐藏层) 
![|239](https://cleverbobo.github.io/2020/08/30/bp/13.png)  
超参数是**隐藏层数**和**隐藏层大小**

- **单层感知机**适合处理简单的、线性可分的二分类问题，即所有数据点可以通过一条直线（或高维空间中的超平面）分开。
- **多层感知机**通过增加**隐藏层**和使用**非线性激活函数**，可以处理更复杂的非线性问题，适用于多类分类、复杂回归等广泛的应用场景。

```
net = nn.Sequential(nn.Flatten(),
                    nn.Linear(784, 256),
                    nn.ReLU(),
                    nn.Linear(256, 10))
```
# 3. 为什么需要神经网络

虽然**多项式回归**通过引入多项式特征可以拟合非线性数据，但它与神经网络在以下方面有显著区别：

1. **特征扩展 vs. 层叠变换：**
	
	- **多项式回归：** 需要手动扩展特征空间，引入高次项和交叉项，维度可能迅速增加。
	- **神经网络：** 通过层叠的非线性变换自动学习特征表示，能够捕捉更复杂的特征关系，通常更高效。
2. **模型灵活性：**
	
	- **多项式回归：** 适用于低维度且特征关系简单的场景，难以扩展到高维和复杂数据。
	- **神经网络：** 尤其是深层网络，能够处理高维、复杂的数据，如图像、音频、文本等。
3. **参数优化：**
	
	- **多项式回归：** 参数数量随特征扩展呈多项式增长，可能导致过拟合。
	- **神经网络：** 通过层与层之间的权重共享和局部连接，更有效地管理参数数量。