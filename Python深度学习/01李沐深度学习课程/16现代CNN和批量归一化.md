现代几个基础的卷积神经网络
https://zh.d2l.ai/chapter_convolutional-modern/index.html

批量归一化BN
用到激活函数之前，有一个说法是用到之后（？）
我们在神经网络中遇到的问题是内部协变量偏移。当我们训练神经网络时，数据分布会发生变化，模型训练速度会变慢。这个问题被定义为内部协变量偏移。为了保持数据的相似分布，我们使用批量归一化，通过使用平均值=0、标准偏差=1（μ=0，σ=1）对输出进行归一化。与不使用批量归一化的模型相比，通过使用此技术，模型的训练速度更快，并且还提高了模型的准确性。