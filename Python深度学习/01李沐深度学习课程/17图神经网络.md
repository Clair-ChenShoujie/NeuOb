
https://www.betteryeah.com/blog/what-is-graph-neural-network

https://pattern.swarma.org/article/52

# 1. 图神经网络和图结构学习
## 一、定义与基本概念

### 1. 图神经网络（GNN）

**定义**：图神经网络是一类专门用于处理图结构数据的神经网络模型。GNN通过节点及其连接关系（边）来捕捉图中节点的特征和结构信息，从而进行节点分类、图分类、链接预测等任务。

**核心思想**：通过消息传递机制（Message Passing），在图的拓扑结构中传播和聚合节点特征，实现对图数据的深度学习和表示。

### 2. 图结构学习（GSL）

**定义**：图结构学习旨在从数据中自动学习或优化图的结构，即确定节点之间的连接关系（边）。GSL主要关注图的构建和优化，而不是在给定图结构上进行学习任务。

**核心思想**：通过算法或模型，从原始数据中挖掘潜在的图结构，提升下游任务（如分类、聚类）的性能，或适应动态变化的图数据。

## 二、主要目标

### 1. 图神经网络（GNN）

- **表征学习**：学习节点、边或整个图的高维表示（embedding），以便进行下游任务。
- **任务导向**：专注于在既定图结构上执行特定任务，如节点分类、图分类、链接预测等。
- **捕捉结构信息**：通过图的拓扑结构和节点特征的结合，提升模型的表达能力。

### 2. 图结构学习（GSL）

- **图构建与优化**：从原始数据中构建图结构，或在已有图结构上进行优化。
- **增强表示**：通过改进图结构，提高下游任务的性能。
- **适应变化**：处理图结构的动态变化，如动态社交网络中的关系更新。

## 三、方法与技术

### 1. 图神经网络（GNN）的方法

- **消息传递机制（Message Passing）**：
  
  每一层GNN通过聚合邻居节点的信息来更新节点表示。这一过程可以形式化为：

  $$
  \mathbf{h}_v^{(k)} = \text{UPDATE}^{(k)}\left(\mathbf{h}_v^{(k-1)}, \text{AGGREGATE}^{(k)}\left(\{\mathbf{h}_u^{(k-1)} | u \in \mathcal{N}(v)\}\right)\right)
  $$

  其中，$\mathbf{h}_v^{(k)}$ 表示节点 $v$ 在第 $k$ 层的表示，$\mathcal{N}(v)$ 是节点 $v$ 的邻居集合。

- **常见模型**：

  - **GCN（Graph Convolutional Network）**：利用谱图理论进行卷积操作。
  - **GraphSAGE**：采用采样和聚合的方法处理大规模图数据。
  - **GAT（Graph Attention Network）**：引入注意力机制，赋予不同邻居不同的权重。

### 2. 图结构学习（GSL）的方法

- **基于规则的方法**：

  利用领域知识或预定义规则构建图结构。例如，在社交网络中，基于用户的共同兴趣建立连接。

- **基于相似度的方法**：

  根据节点特征之间的相似度或距离来确定边的存在。常用的方法包括K近邻（K-NN）、阈值剪枝等。

- **联合学习方法**：

  将图结构学习与下游任务（如分类、回归）联合起来，通过优化目标函数同时学习图结构和任务模型。例如，学习一个图结构使得GNN在节点分类任务上表现最好。

- **生成模型**：

  使用生成对抗网络（GAN）或变分自编码器（VAE）等生成模型来生成或优化图结构。

## 四、实际案例

### 1. 图神经网络（GNN）案例

**节点分类**：

在学术合作网络中，预测研究人员的研究领域。GNN通过聚合邻居节点（合作伙伴）的研究领域信息，学习每个研究人员的表示，从而进行分类。

**代码示例（基于PyTorch Geometric）**：

```python
import torch
import torch.nn.functional as F
from torch_geometric.nn import GCNConv

class GCN(torch.nn.Module):
    def __init__(self, num_features, hidden_dim, num_classes):
        super(GCN, self).__init__()
        self.conv1 = GCNConv(num_features, hidden_dim)
        self.conv2 = GCNConv(hidden_dim, num_classes)

    def forward(self, data):
        x, edge_index = data.x, data.edge_index
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = self.conv2(x, edge_index)
        return F.log_softmax(x, dim=1)
```

### 2. 图结构学习（GSL）案例

**社交网络图构建**：

基于用户的兴趣相似度构建社交网络图，以提升推荐系统的性能。通过计算用户兴趣向量的余弦相似度，连接相似度高于某阈值的用户。

**代码示例**：

```python
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import networkx as nx

# 假设 user_features 是一个 N x D 的矩阵，N 为用户数，D 为特征维度
user_features = np.random.rand(100, 50)

# 计算相似度矩阵
similarity_matrix = cosine_similarity(user_features)

# 构建图
G = nx.Graph()
num_users = user_features.shape[0]
for i in range(num_users):
    for j in range(i + 1, num_users):
        if similarity_matrix[i, j] > 0.8:  # 设定相似度阈值
            G.add_edge(i, j, weight=similarity_matrix[i, j])
```

## 五、总结

- **图神经网络GNN**主要关注在给定或构建好的图结构上，通过深度学习方法进行节点、边或图的表示学习和下游任务处理。
  
- **图结构学习GSL**则侧重于从数据中学习或优化图的结构，以提高图数据的表示效果和下游任务的性能。

两者在图数据处理链条中可以相辅相成：GSL负责构建或优化图结构，GNN则在优化后的图结构上进行高效的表示学习和任务执行。