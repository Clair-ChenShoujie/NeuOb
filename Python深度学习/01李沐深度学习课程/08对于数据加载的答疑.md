前向传播## 一、PyTorch 中数据加载的基本概念

在 PyTorch 中，数据的加载主要依赖于两个核心类：

1. **`Dataset`**：负责数据的存取与预处理。
2. **`DataLoader`**：负责数据的批量加载、打乱以及多线程数据加载。

通过这两个类，PyTorch 能够高效地处理大规模数据集，并在训练过程中动态地提供数据。

## 二、加载数据集的步骤

### 1. 导入必要的库

首先，确保你已经安装了 PyTorch。如果没有，可以通过以下命令安装：

```bash
pip install torch torchvision
```

然后，在代码中导入所需的库：

```python
import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
```

### 2. 定义数据预处理（Transforms）

通常，原始数据需要经过一定的预处理才能输入到模型中。`transforms` 提供了一系列常用的预处理方法，如归一化、裁剪、旋转等。

```python
transform = transforms.Compose([
    transforms.ToTensor(),  # 将图片转换为 Tensor
    transforms.Normalize((0.5,), (0.5,))  # 归一化，均值为0.5，标准差为0.5
])
```

### 3. 加载数据集

PyTorch 的 `torchvision.datasets` 提供了许多常用的数据集，如 MNIST、CIFAR-10 等。以 MNIST 为例：

```python
train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)
```

- `root`：数据集的存储路径。
- `train`：是否加载训练集。
- `download`：如果数据集不存在，是否下载。
- `transform`：应用到数据上的预处理。

### 4. 创建 DataLoader

`DataLoader` 将 `Dataset` 封装起来，提供批量数据加载、打乱数据和并行加载数据的功能。

```python
train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)
```

- `dataset`：要加载的数据集。
- `batch_size`：每个批次的数据量。
- `shuffle`：是否在每个 epoch 开始前打乱数据。

### 5. 使用 DataLoader 进行迭代训练

在训练和测试过程中，可以通过迭代 `DataLoader` 来获取数据。

```python
for images, labels in train_loader:
    # 这里的 images 是一个批次的图像数据，labels 是对应的标签
    # 进行前向传播、反向传播和参数更新
    pass
```
