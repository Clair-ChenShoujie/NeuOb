# 1.线性回归步骤
这一块懂原理就行，不需要手撕
## 1. 线性回归简介

**线性回归（Linear Regression）** 是一种基本的监督学习算法，用于预测连续型目标变量。它假设目标变量与一个或多个特征（输入变量）之间存在线性关系。数学表达式为：
$$
\mathbf{y} = \mathbf{X}\mathbf{w} + b + \epsilon
$$

其中：
- \(\mathbf{X}\) 是输入特征矩阵。
- \(\mathbf{w}\) 是模型权重向量。
- \(b\) 是偏置（截距）。
- \(\epsilon\) 是噪声项，通常假设服从均值为0的正态分布。

目标是通过训练数据来估计参数 $\mathbf{w}$和$b$，使得模型对新数据的预测尽可能准确。
### 线性回归的流程图
#梯度下降
![[0b7c1aac0459f546f162b973aebf2c84.png|575]]

## 2. 数据生成

首先，我们需要生成一个合成数据集来模拟线性回归的场景。

### 代码解析

```python
import torch
from d2l import torch as d2l

def synthetic_data(w, b, num_examples):
    """生成 y = Xw + b + 噪声"""
    X = torch.normal(0, 1, (num_examples, len(w)))
    y = torch.matmul(X, w) + b
    y += torch.normal(0, 0.01, y.shape)
    return X, y.reshape((-1, 1))

# 真实参数
true_w = torch.tensor([2, -3.4])
true_b = 4.2

# 生成1000个样本
features, labels = synthetic_data(true_w, true_b, 1000)

print('features:', features[0], '\nlabel:', labels[0])
```

### 详细说明

1. **导入必要的库**：
    - `torch`: PyTorch 的核心库，用于张量操作和构建神经网络。
    - `d2l`: 《动手学深度学习》中的辅助库，方便绘图和其他功能。

2. **生成数据函数 `synthetic_data`**：
    - **输入**：
        - `w`: 权重向量。
        - `b`: 偏置。
        - `num_examples`: 样本数量。
    - **过程**：
        - `X = torch.normal(0, 1, (num_examples, len(w)))`：
            - 从均值为0、标准差为1的正态分布中生成形状为 `(num_examples, len(w))` 的特征矩阵 `X`。
        - `y = torch.matmul(X, w) + b`：
            - 计算线性组合，得到标签 `y`。
        - `y += torch.normal(0, 0.01, y.shape)`：
            - 添加均值为0、标准差为0.01的噪声，模拟现实中的观测误差。
        - `return X, y.reshape((-1, 1))`：
            - 返回特征和标签，将 `y` 的形状调整为 `(num_examples, 1)`。

3. **设置真实参数并生成数据**：
    - `true_w = torch.tensor([2, -3.4])`：真实权重。
    - `true_b = 4.2`：真实偏置。
    - `features, labels = synthetic_data(true_w, true_b, 1000)`：生成1000个样本的数据集。

4. **输出第一个样本**：
    - `print('features:', features[0], '\nlabel:', labels[0])`：
        - 打印第一个样本的特征和标签，帮助我们直观理解数据。

## 3. 可视化数据

通过散点图可以直观地观察特征与标签之间的关系。

### 代码解析

```python
d2l.set_figsize()
d2l.plt.scatter(features[:, (1)].detach().numpy(), labels.detach().numpy(), 1)
```

### 详细说明

- `d2l.set_figsize()`：设置图像大小，确保图表清晰。
- `d2l.plt.scatter(...)`：绘制散点图。
    - `features[:, (1)]`：选择第2个特征（索引从0开始）。
    - `labels`：标签值。
    - `detach().numpy()`：将张量从计算图中分离并转换为NumPy数组，以便绘图。
    - `1`：设置散点的大小。

**示例图像**：

![散点图示例|367](https://zh-v2.d2l.ai/_images/output_linear-regression-scratch_58de05_48_0.svg)

这一图像展示了第二个特征与标签之间的线性关系，符合线性回归模型的假设。

## 4. 数据集迭代器

在训练模型时，我们通常将数据集划分为多个小批量（mini-batch）进行训练，特别是在大规模数据集上。这里我们定义一个 `data_iter` 函数，用于生成小批量的数据。

### 代码解析

```python
def data_iter(batch_size, features, labels):
    num_examples = len(features)
    indices = list(range(num_examples))
    random.shuffle(indices)  # 打乱数据顺序
    for i in range(0, num_examples, batch_size):
        batch_indices = torch.tensor(
            indices[i: min(i + batch_size, num_examples)]
        )
        yield features[batch_indices], labels[batch_indices]
```

### 详细说明

1. **参数**：
    - `batch_size`：每个小批量的样本数量。
    - `features`：特征矩阵。
    - `labels`：标签向量。

2. **过程**：
    - `num_examples = len(features)`：获取数据集中样本数量。
    - `indices = list(range(num_examples))`：创建索引列表。
    - `random.shuffle(indices)`：随机打乱索引，确保每个epoch的数据顺序不同，增加模型的泛化能力。
    - `for i in range(0, num_examples, batch_size)`：
        - 按照 `batch_size` 步长遍历数据集。
    - `batch_indices = torch.tensor(indices[i: min(i + batch_size, num_examples)])`：
        - 获取当前批次的索引。
    - `yield features[batch_indices], labels[batch_indices]`：
        - 生成当前批次的特征和标签。

3. **示例使用**：

```python
batch_size = 10
for X, y in data_iter(batch_size, features, labels):
    print(X, '\n', y)
    break
```

这段代码打印第一个小批量的数据，帮助我们理解数据迭代的效果。

## 5. 初始化模型参数

在训练之前，需要初始化模型参数（权重和偏置）。通常权重从一个较小的随机数（如正态分布）初始化，偏置可以初始化为0。

### 代码解析

```python
w = torch.normal(0, 0.01, size=(2, 1), requires_grad=True)
b = torch.zeros(1, requires_grad=True)
```

### 详细说明

1. **权重 `w`**：
    - `torch.normal(0, 0.01, size=(2, 1))`：从均值为0、标准差为0.01的正态分布中生成形状为 `(2, 1)` 的权重张量。
    - `requires_grad=True`：设置 `w` 需要计算梯度，用于后续的梯度下降。

2. **偏置 `b`**：
    - `torch.zeros(1)`：初始化为0。
    - `requires_grad=True`：设置 `b` 需要计算梯度。

**注意**：在不同的深度学习框架中（如 TensorFlow、Paddle 等），初始化参数的方式可能略有不同，但核心思想相同。

## 6. 定义模型

定义线性回归模型，模型的输出是输入特征与权重的线性组合再加上偏置。

### 代码解析

```python
def linreg(X, w, b):
    """线性回归模型"""
    return torch.matmul(X, w) + b
```

### 详细说明

1. **函数 `linreg`**：
    - **输入**：
        - `X`：输入特征。
        - `w`：权重。
        - `b`：偏置。
    - **输出**：
        - 模型预测值 \( y_{\text{hat}} = Xw + b \)。

2. ** `torch.matmul(X, w)`**：
    - 矩阵乘法，将批量特征 `X` 与权重 `w` 相乘，得到线性组合部分。

3. **`+ b`**：
    - 将偏置 `b` 加到每个预测值上。由于 `b` 是标量，PyTorch 会自动广播到每个样本。

## 7. 定义损失函数

损失函数用于衡量模型预测值与真实值之间的差距。这里使用的是 **均方损失（Mean Squared Error, MSE）**。

### 代码解析

```python
def squared_loss(y_hat, y):
    """均方损失"""
    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2
```

### 详细说明

1. **函数 `squared_loss`**：
    - **输入**：
        - `y_hat`：模型预测值。
        - `y`：真实值。
    - **输出**：
        - 每个样本的平方损失。
    - **过程**：
        - `y.reshape(y_hat.shape)`：将真实值的形状调整为与预测值相同，确保可以进行逐元素运算。
        - `(y_hat - y.reshape(y_hat.shape)) ** 2`：计算预测值与真实值的平方差。
        - `/ 2`：将平方差除以2，方便后续计算梯度。

**为什么除以2**：
- 在进行梯度计算时，均方差的导数会多一个2，除以2可以简化梯度表达式，使其更为简洁。

## 8. 定义优化算法

在这里，我们使用 **小批量随机梯度下降（Stochastic Gradient Descent, SGD）** 作为优化器，用于更新模型参数。

### 代码解析

```python
def sgd(params, lr, batch_size):
    """小批量随机梯度下降"""
    with torch.no_grad():
        for param in params:
            param -= lr * param.grad / batch_size
            param.grad.zero_()
```

### 详细说明

1. **函数 `sgd`**：
    - **输入**：
        - `params`：模型的参数列表（如 `[w, b]`）。
        - `lr`：学习率，控制每次参数更新的步长。
        - `batch_size`：当前小批量的样本数量。
    - **过程**：
        - `with torch.no_grad()`：在没有梯度计算的上下文中进行参数更新，避免这些操作被记录到计算图中。
        - `for param in params`：遍历每个参数。
            - `param -= lr * param.grad / batch_size`：更新参数，按照梯度下降的方向移动。
                - `lr * param.grad / batch_size`：学习率乘以梯度，再除以批量大小，确保步长不受批量大小影响。
            - `param.grad.zero_()`：将梯度清零，为下一次迭代做准备。

**注意**：
- 使用 `torch.no_grad()` 是因为参数更新过程不需要梯度计算，且可以节省内存和计算资源。
- 除以 `batch_size` 的原因是损失函数是所有样本的总和，而不是均值。这确保了步长的稳定性。

## 9. 训练模型

现在，我们将把所有部分结合起来，完成模型的训练过程。

### 代码解析

```python
lr = 0.03
num_epochs = 3
net = linreg
loss = squared_loss

for epoch in range(num_epochs):
    for X, y in data_iter(batch_size, features, labels):
        with torch.enable_grad():
            l = loss(net(X, w, b), y)  # 计算小批量的损失
        l.sum().backward()  # 计算损失关于参数的梯度
        sgd([w, b], lr, batch_size)  # 更新参数
    with torch.no_grad():
        train_l = loss(net(features, w, b), labels)
        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')
```

### 详细说明

1. **超参数设置**：
    - `lr = 0.03`：学习率。
    - `num_epochs = 3`：训练的轮数（epoch）。
    - `net = linreg`：模型函数。
    - `loss = squared_loss`：损失函数。

2. **训练循环**：
    - `for epoch in range(num_epochs)`：遍历每个 epoch。
        - `for X, y in data_iter(batch_size, features, labels)`：遍历每个小批量数据。
            - **前向传播和损失计算**：
                - `with torch.enable_grad()`：启用梯度计算。
                - `l = loss(net(X, w, b), y)`：计算当前小批量的损失。
            - **反向传播**：
                - `l.sum().backward()`：计算损失关于参数的梯度。
            - **参数更新**：
                - `sgd([w, b], lr, batch_size)`：使用 SGD 更新参数。
    - **评估和打印损失**：
        - `with torch.no_grad()`：禁用梯度计算。
        - `train_l = loss(net(features, w, b), labels)`：计算整个数据集的损失。
        - `print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')`：打印当前 epoch 的平均损失。

3. **训练结果**：

```
epoch 1, loss 0.024969
epoch 2, loss 0.000089
epoch 3, loss 0.000051
```

这表明随着训练的进行，损失逐渐减少，模型参数逐步逼近真实值。

4. **训练不同版本的代码**：

在提供的内容中，不同深度学习框架（如 TensorFlow、Paddle）有不同的实现方式。对于 PyTorch，有两种训练循环的实现方式：

- 第一种方式：

    ```python
    with autograd.record():
        l = loss(net(X, w, b), y)
    l.backward()
    sgd([w, b], lr, batch_size)
    ```

- 第二种方式：

    ```python
    with torch.no_grad():
        train_l = loss(net(features, w, b), labels)
        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')
    ```

这里主要差异在于是否启用梯度计算的上下文，但核心思想一致。

## 10. 评估训练结果

在训练结束后，我们可以比较模型学到的参数与真实参数之间的差异，以评估训练的效果。

### 代码解析

```python
print(f'w的估计误差: {true_w - w.reshape(true_w.shape)}')
print(f'b的估计误差: {true_b - b}')
```

### 详细说明

1. **打印权重误差**：
    - `w.reshape(true_w.shape)`：将学习到的权重形状调整为与真实权重相同。
    - `true_w - w.reshape(true_w.shape)`：计算估计误差。

2. **打印偏置误差**：
    - `true_b - b`：计算偏置的估计误差。

### 预期输出

```
w的估计误差: tensor([-1.3804e-04,  5.7936e-05], grad_fn=<SubBackward0>)
b的估计误差: tensor([0.0006], grad_fn=<RsubBackward1>)
```

**解释**：
- 误差非常小，表明模型成功地学习到了接近真实参数的值。

## 11. 小结

在本节中，我们通过 PyTorch 从零开始实现了线性回归模型，主要包括以下步骤：

1. **生成合成数据**：创建一个带有噪声的线性模型数据集。
2. **定义数据迭代器**：将数据集分成小批量，便于模型训练。
3. **初始化模型参数**：随机初始化权重和偏置。
4. **定义模型**：线性回归函数。
5. **定义损失函数**：均方损失，用于衡量预测误差。
6. **定义优化算法**：小批量随机梯度下降，用于更新模型参数。
7. **训练模型**：通过多轮迭代，不断优化参数，最小化损失函数。
8. **评估结果**：比较学习到的参数与真实参数，验证模型的有效性。

掌握这些基本步骤后，您可以进一步探索更复杂的模型和优化算法，并学习如何利用 PyTorch 提供的高级 API 进行更高效的模型开发。

## 12. 练习解答（可选）

为了巩固所学知识，您可以尝试以下练习：

1. **权重初始化为零**：
    - 如果将权重初始化为零，模型的梯度计算将在每个参数上是相同的，导致所有权重同时更新，可能无法有效地学习到不同的特征对应的权重，因此算法可能无法有效收敛。

2. **自动微分学习电压和电流的关系**：
    - 可以，自动微分能够计算任意复杂函数的梯度，只要你能定义模型和损失函数，就可以用它来学习参数。

3. **基于普朗克定律使用光谱能量密度确定温度**：
    - 这是一个回归问题，可以使用线性回归或更复杂的模型来拟合光谱能量密度与温度之间的关系。

4. **计算二阶导数的问题及解决**：
    - 计算二阶导数会增加计算复杂度和内存消耗。可以通过限制梯度计算的次数或使用高级优化算法（如Adam）来缓解这些问题。

5. **`squared_loss`中使用`reshape`的原因**：
    - 为了确保预测值和真实值的形状一致，便于逐元素计算平方误差。如果形状不匹配，会导致广播错误或错误的损失计算。

6. **不同学习率的效果**：
    - 学习率过大可能导致训练过程不稳定，损失震荡或发散；学习率过小则会导致收敛速度缓慢。因此，选择合适的学习率至关重要。

7. **样本数不能被批量大小整除的情况**：
    - 最后一批的小批量样本数可能少于 `batch_size`。需要确保迭代器能够处理这种情况，避免索引超出范围或遗漏数据。

通过完成这些练习，您将更深入理解线性回归模型及其在 PyTorch 中的实现细节。

# 2.pytorch实现线性回归
ipynb文件位置：I:\miniconda\envs\d2l\d2l-zh\pytorch\chapter_linear-networks\pytorch线性回归实操.ipynb

```
# 3.定义模型

net = nn.Sequential(
    nn.Linear(2, 1)
)

# 4.初始化模型参数

net[0].weight.data.normal_(0,0.01)
net[0].bias.data.fill_(0)
```

![[01.pytorch线性回归实战.pdf]]