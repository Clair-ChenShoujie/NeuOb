{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BrainUSL: Unsupervised Graph Structure Learning\n",
    "\n",
    "This notebook implements the BrainUSL model from the paper *BrainUSL: Unsupervised Graph Structure Learning for Functional Brain Network Analysis*. It performs unsupervised graph structure learning on fMRI data for MDD/BD diagnosis.\n",
    "\n",
    "## Step 1: Install and Import Dependencies\n",
    "Install required packages:\n",
    "```bash\n",
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "pip install numpy scikit-learn matplotlib\n",
    "```\n",
    "Import libraries and set up the device (GPU/CPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import cosine_similarity\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "setup_seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define Utility Functions\n",
    "These functions compute graph similarities, losses, and metrics:\n",
    "- `corrcoef`: Computes correlation matrix for fMRI signals.\n",
    "- `cos_similar`: Computes cosine similarity between node embeddings.\n",
    "- `sameLoss`: View consistency loss.\n",
    "- `unsupervisedGroupContrast`: Correlation-guided contrastive loss.\n",
    "- `rbfKernel`, `kernelEntry`, `distMatrix`, `graph_similarity`: Graph kernel functions for similarity matrix.\n",
    "- `confusion`: Computes accuracy, sensitivity, specificity, and AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrcoef(data, replace_nan_as=0):\n",
    "    x = data - torch.mean(data, dim=-1, keepdim=True)\n",
    "    cov = x.matmul(x.transpose(-2, -1)) / (x.shape[-1] - 1)\n",
    "    d = cov[:, range(cov.shape[1]), range(cov.shape[1])]\n",
    "    stddev = torch.sqrt(d + 1e-8)  # Avoid zero division\n",
    "    cov /= stddev[:, :, None]\n",
    "    cov /= stddev[:, None, :]\n",
    "    cov = torch.where(torch.isnan(cov), torch.full_like(cov, replace_nan_as), cov)\n",
    "    return cov\n",
    "\n",
    "def confusion(g_turth, predictions):\n",
    "    tn, fp, fn, tp = confusion_matrix(g_turth, predictions).ravel()\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "    sensitivity = (tp) / (tp + fn + 1e-8)\n",
    "    specificity = (tn) / (tn + fp + 1e-8)\n",
    "    auc = metrics.roc_auc_score(g_turth, predictions, average='macro')\n",
    "    return accuracy, sensitivity, specificity, auc\n",
    "\n",
    "def cos_similar(p, q):\n",
    "    sim_matrix = p.matmul(q.transpose(-2, -1))\n",
    "    a = torch.norm(p, p=2, dim=-1)\n",
    "    b = torch.norm(q, p=2, dim=-1)\n",
    "    sim_matrix /= (a.unsqueeze(-1) + 1e-8)\n",
    "    sim_matrix /= (b.unsqueeze(-2) + 1e-8)\n",
    "    sim_matrix = torch.where(torch.isnan(sim_matrix), torch.full_like(sim_matrix, 0), sim_matrix)\n",
    "    return sim_matrix\n",
    "\n",
    "def sameLoss(x, x_aug):\n",
    "    x_abs = x.norm(dim=1)\n",
    "    x_aug_abs = x_aug.norm(dim=1)\n",
    "    loss = 2 - cosine_similarity(x, x_aug, dim=-1).mean() - cosine_similarity(x_abs, x_aug_abs, dim=-1).mean()\n",
    "    return loss\n",
    "\n",
    "def unsupervisedGroupContrast(x, x_aug, label, T=0.4):\n",
    "    x_abs = x.norm(dim=1)\n",
    "    x_aug_abs = x_aug.norm(dim=1)\n",
    "    sim_matrix1 = torch.einsum('ik,jk->ij', x, x) / torch.einsum('i,j->ij', x_abs, x_abs)\n",
    "    sim_matrix1 = torch.exp(sim_matrix1 / T)\n",
    "    sim_matrix2 = torch.einsum('ik,jk->ij', x_aug, x_aug) / torch.einsum('i,j->ij', x_aug_abs, x_aug_abs)\n",
    "    sim_matrix2 = torch.exp(sim_matrix2 / T)\n",
    "    sim_matrix = torch.cat([sim_matrix1, sim_matrix2], dim=0)\n",
    "    pos_label = label.tile(dims=[2, 1])\n",
    "    neg_label = (1 - pos_label)\n",
    "    pos = sim_matrix[pos_label.bool()].mean() + 1\n",
    "    neg = sim_matrix[neg_label.bool()].sum() / (neg_label.sum() - neg_label.shape[0] + 1e-8) + 1\n",
    "    loss = -torch.log(pos / neg)\n",
    "    return loss\n",
    "\n",
    "def rbfKernel(bag1, bag2, gamma):\n",
    "    n, m = bag1.shape[0], bag2.shape[0]\n",
    "    bag1_i_norm = torch.sum(bag1 ** 2, dim=1)\n",
    "    bag2_i_norm = torch.sum(bag2 ** 2, dim=1)\n",
    "    distMat = torch.tile(bag1_i_norm, [m, 1]).T + torch.tile(bag2_i_norm, [n, 1]) - 2 * bag1.matmul(bag2.T)\n",
    "    kMat = torch.exp(-gamma * distMat)\n",
    "    return kMat\n",
    "\n",
    "def kernelEntry(bag1, bag2, weightMatrix1, weightMatrix2, gamma):\n",
    "    n, m = bag1.shape[0], bag2.shape[0]\n",
    "    activeEdgesCount1 = weightMatrix1.sum(dim=1)\n",
    "    activeEdgesCount2 = weightMatrix2.sum(dim=1)\n",
    "    activeEdgesCoef1 = 1. / (activeEdgesCount1 + 1e-3)\n",
    "    activeEdgesCoef2 = 1. / (activeEdgesCount2 + 1e-3)\n",
    "    k = rbfKernel(bag1, bag2, gamma=gamma)\n",
    "    k = torch.tile(activeEdgesCoef1, dims=[m, 1]).T * torch.tile(activeEdgesCoef2, dims=[n, 1]) * k\n",
    "    k = torch.sum(k) / torch.sqrt(torch.sum(activeEdgesCoef1)) / torch.sqrt(torch.sum(activeEdgesCoef2))\n",
    "    return k\n",
    "\n",
    "def distMatrix(bag, method='gaussian', gamma=1):\n",
    "    n = bag.shape[0]\n",
    "    bag_i_norm = torch.sum(bag ** 2, dim=1)\n",
    "    distMat = torch.tile(bag_i_norm, [n, 1]) + torch.tile(bag_i_norm, [n, 1]).T - 2 * bag.matmul(bag.T)\n",
    "    if method == 'gaussian':\n",
    "        distMat = 1 - torch.exp(-gamma * distMat)\n",
    "    return distMat\n",
    "\n",
    "def graph_similarity(bag, method='gaussian', gamma=1):\n",
    "    n = bag.shape[0]\n",
    "    graph_kernel = torch.zeros(size=(n, n))\n",
    "    w = torch.zeros_like(bag)\n",
    "    for wi in range(n):\n",
    "        w[wi] = distMatrix(bag[wi])\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            mat = kernelEntry(bag[i], bag[j], w[i], w[j], 0.5)\n",
    "            graph_kernel[i][j] = mat\n",
    "            graph_kernel[j][i] = mat\n",
    "    return graph_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define Model Classes\n",
    "- `SigCNN`: Graph generation module with 1D convolutions and learnable adjacency matrix (`w`) for sparse graphs.\n",
    "- `E2E`: Topology-aware encoder with cross-shaped filters to capture edge-to-node information.\n",
    "- `Model`: Combines `SigCNN`, `E2E`, and a linear classifier. Supports pre-training (unsupervised) and fine-tuning (supervised)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigCNN(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(SigCNN, self).__init__()\n",
    "        self.in_channel = in_channel\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channel, out_channels=out_channel, kernel_size=10)\n",
    "        self.conv2 = nn.Conv1d(in_channels=out_channel, out_channels=out_channel, kernel_size=15)\n",
    "        self.bn = nn.BatchNorm1d(116, affine=True)\n",
    "        self.bn2 = nn.BatchNorm1d(116, affine=True)\n",
    "        self.alpha = 1\n",
    "        self.beta = 1\n",
    "        self.w = nn.Parameter(torch.FloatTensor(116, 116), requires_grad=True)\n",
    "        nn.init.uniform_(self.w, a=0, b=1)\n",
    "\n",
    "    def _normalize(self, mx):\n",
    "        rowsum = mx.sum(1)\n",
    "        r_inv = rowsum.pow(-1 / 2).flatten()\n",
    "        r_inv[torch.isinf(r_inv)] = 0.\n",
    "        r_mat_inv = torch.diag(r_inv)\n",
    "        mx = r_mat_inv @ mx\n",
    "        mx = mx @ r_mat_inv\n",
    "        return mx\n",
    "\n",
    "    def get_w_data(self):\n",
    "        w = self.grad_w()\n",
    "        return w.data\n",
    "\n",
    "    def grad_w(self):\n",
    "        w = self._normalize(self.w)\n",
    "        w = F.relu(self.bn2(w))\n",
    "        w = (w + w.T) / 2\n",
    "        return w\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x).reshape(x.shape[0], self.in_channel, -1)\n",
    "        x = cos_similar(x, x)\n",
    "        w = self._normalize(self.w)\n",
    "        w = F.relu(self.bn2(w))\n",
    "        w = (w + w.T) / 2\n",
    "        l1 = torch.norm(w, p=1, dim=1).mean()\n",
    "        x = w * x\n",
    "        return x, l1\n",
    "\n",
    "class E2E(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, input_shape):\n",
    "        super().__init__()\n",
    "        self.in_channel = in_channel\n",
    "        self.out_channel = out_channel\n",
    "        self.d = input_shape[0]\n",
    "        self.conv1xd = nn.Conv2d(in_channel, out_channel, (self.d, 1))\n",
    "        self.convdx1 = nn.Conv2d(in_channel, out_channel, (1, self.d))\n",
    "\n",
    "    def forward(self, A):\n",
    "        A = A.view(-1, self.in_channel, 116, 116)\n",
    "        a = self.conv1xd(A)\n",
    "        b = self.convdx1(A)\n",
    "        concat1 = torch.cat([a] * self.d, 2)\n",
    "        concat2 = torch.cat([b] * self.d, 3)\n",
    "        return concat1 + concat2\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, dropout=0.5, num_class=2, out_channel=116*2):\n",
    "        super().__init__()\n",
    "        self.e2e = nn.Sequential(\n",
    "            E2E(1, 8, (116, 116)),\n",
    "            nn.LeakyReLU(0.33),\n",
    "            E2E(8, 8, (116, 116)),\n",
    "            nn.LeakyReLU(0.33),\n",
    "        )\n",
    "        self.e2n = nn.Sequential(\n",
    "            nn.Conv2d(8, 48, (1, 116)),\n",
    "            nn.LeakyReLU(0.33)\n",
    "        )\n",
    "        self.n2g = nn.Sequential(\n",
    "            nn.Conv2d(48, 116, (116, 1)),\n",
    "            nn.LeakyReLU(0.33)\n",
    "        )\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(116, 64),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.LeakyReLU(0.33),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.Linear(32, 10),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.LeakyReLU(0.33),\n",
    "            nn.Linear(10, num_class)\n",
    "        )\n",
    "        for layer in self.linear:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.kaiming_uniform_(layer.weight)\n",
    "                nn.init.zeros_(layer.bias)\n",
    "        self.sigcnn = SigCNN(in_channel=116, out_channel=out_channel)\n",
    "\n",
    "    def net(self, x):\n",
    "        x = self.e2e(x)\n",
    "        x = self.e2n(x)\n",
    "        return x\n",
    "\n",
    "    def Line(self, x):\n",
    "        x = self.n2g(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        x = F.softmax(x, dim=-1)\n",
    "        return x\n",
    "\n",
    "    def get_label_matrix_from_sim(self, adj, y=None, phi=0.0017):\n",
    "        sim_matrix = graph_similarity(adj)\n",
    "        if y is not None:\n",
    "            rate = sum(y) / len(y)\n",
    "            node_num = len(y) ** 2\n",
    "            value = sim_matrix.sort(descending=True)[0]\n",
    "            index = int(rate * node_num)\n",
    "            phi = value[index]\n",
    "        sim_matrix = (sim_matrix >= phi).int()\n",
    "        return sim_matrix\n",
    "\n",
    "    def pre_train(self, x):\n",
    "        x1 = corrcoef(x)\n",
    "        group_label = self.get_label_matrix_from_sim(adj=x1, phi=0.0017)\n",
    "        x, loss = self.sigcnn(x)\n",
    "        x = self.net(x)\n",
    "        x1 = self.net(x1)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x1 = x1.view(x1.shape[0], -1)\n",
    "        same = sameLoss(x, x1)\n",
    "        super_loss = unsupervisedGroupContrast(x, x1, group_label)\n",
    "        return [super_loss, same, 0.3 * loss]\n",
    "\n",
    "    def base_net(self, x):\n",
    "        x = self.net(x)\n",
    "        x = self.Line(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, y=None, pre=False):\n",
    "        if pre:\n",
    "            return self.pre_train(x)\n",
    "        else:\n",
    "            return self.base_net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Load and Inspect Data\n",
    "Load the fMRI dataset (`MDD_HC_sig.npy`, `MDD_HC_label.npy`) and verify shapes.\n",
    "- Expected: `X` shape `(299, 116, T)`, `Y` shape `(299,)`.\n",
    "- Transpose `X` to `(N, T, 116)` as required by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "---------------------\n",
      "X shape: (427, 116, 950)\n",
      "Y shape: (427,)\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "source_data = 'MDD'\n",
    "print('Loading data...')\n",
    "X = np.load(f'./datasets/new/{source_data}_HC_sig.npy')\n",
    "Y = np.load(f'./datasets/new/{source_data}_HC_label.npy')\n",
    "X = torch.from_numpy(X).permute([0, 2, 1]).numpy()  # (N, T, 116) -> (N, 116, T)\n",
    "\n",
    "print('---------------------')\n",
    "print('X shape:', X.shape)\n",
    "print('Y shape:', Y.shape)\n",
    "print('---------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Set Hyperparameters\n",
    "Define training parameters:\n",
    "- `pre_epo=10`: Pre-training epochs (consider increasing to 40–60 per paper).\n",
    "- `epochs=60`: Total epochs (10 pre-training + 50 fine-tuning).\n",
    "- `batch_size=32`: Batch size for fine-tuning.\n",
    "- `pre_batch=32`: Batch size for pre-training.\n",
    "- `lr=0.001`, `decay=0.01`: Learning rate and weight decay.\n",
    "- `n_split=5`: 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_epo = 10\n",
    "epochs = 50 + pre_epo\n",
    "batch_size = 32\n",
    "pre_batch = 32\n",
    "dropout = 0.5\n",
    "lr = 0.001\n",
    "decay = 0.01\n",
    "n_split = 5\n",
    "result = []\n",
    "result_auc = []\n",
    "result_sen = []\n",
    "result_spec = []\n",
    "os.makedirs('outputs', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Training Loop (Single Fold for Demonstration)\n",
    "Run a single fold of 5-fold cross-validation to understand the process. Later, extend to 5 runs × 5 folds.\n",
    "- Pre-training: Uses unsupervised losses (contrastive, view consistency, L1 sparsity).\n",
    "- Fine-tuning: Uses cross-entropy loss.\n",
    "- Evaluate on validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 1\n",
      "X_train shape: (272, 116, 950)\n",
      "X_val shape: (69, 116, 950)\n",
      "X_test shape: (86, 116, 950)\n",
      "Y_train shape: (272,)\n",
      "Y_val shape: (69,)\n",
      "Y_test shape: (86,)\n",
      "Epoch 1, Pre-training loss: 12.9906, Sparse rate: 0.7459\n",
      "Epoch 2, Pre-training loss: 12.9425, Sparse rate: 0.7459\n",
      "Epoch 3, Pre-training loss: 12.8806, Sparse rate: 0.7459\n",
      "Epoch 4, Pre-training loss: 12.8269, Sparse rate: 0.7459\n",
      "Epoch 5, Pre-training loss: 12.7833, Sparse rate: 0.7458\n",
      "Epoch 6, Pre-training loss: 12.7446, Sparse rate: 0.7453\n",
      "Epoch 7, Pre-training loss: 12.7069, Sparse rate: 0.7452\n",
      "Epoch 8, Pre-training loss: 12.6700, Sparse rate: 0.7447\n",
      "Epoch 9, Pre-training loss: 12.6376, Sparse rate: 0.7438\n",
      "Epoch 10, Pre-training loss: 12.6014, Sparse rate: 0.7433\n",
      "Epoch 20, Train loss: 0.6885, Val acc: 0.6377\n",
      "Epoch 30, Train loss: 0.6886, Val acc: 0.6377\n",
      "Epoch 40, Train loss: 0.6915, Val acc: 0.6377\n",
      "Epoch 50, Train loss: 0.6917, Val acc: 0.6377\n",
      "Epoch 60, Train loss: 0.6874, Val acc: 0.6377\n",
      "Test acc: 0.6163, AUC: 0.5000, Sensitivity: 0.0000, Specificity: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Single fold for demonstration\n",
    "\n",
    "# 含义: 固定随机种子（这里是 0），\n",
    "# 确保每次运行代码时，数据的随机划分和模型的初始化都相同。\n",
    "# 这样可以让实验结果可重复，便于调试和比较。\n",
    "setup_seed(0)\n",
    "\n",
    "# 创建一个 K 折交叉验证对象（假设 n_split=5），shuffle=True 表示在划分前打乱数据。\n",
    "kf = KFold(n_splits=n_split, shuffle=True)\n",
    "kfold_index = 1\n",
    "\n",
    "# 获取 5 折中的第一折的索引。这会将数据分为 80% 的训练验证集（trainval_index）和 20% 的测试集（test_index）。\n",
    "# kf.split(X, Y) 分别生成 K 对索引，比如 X 分为 k-1:1 ，这里next只取第一对作为demo\n",
    "trainval_index, test_index = next(kf.split(X, Y))\n",
    "X_trainval, X_test = X[trainval_index], X[test_index]\n",
    "Y_trainval, Y_test = Y[trainval_index], Y[test_index]\n",
    "\n",
    "# 进一步将训练验证集拆分为训练集和验证集\n",
    "kf_inner = KFold(n_splits=n_split, shuffle=True)\n",
    "train_index, val_index = next(kf_inner.split(X_trainval, Y_trainval))\n",
    "X_train, X_val = X_trainval[train_index], X_trainval[val_index]\n",
    "Y_train, Y_val = Y_trainval[train_index], Y_trainval[val_index]\n",
    "\n",
    "print(f'kfold_index: {kfold_index}')\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_val shape:', X_val.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print('Y_val shape:', Y_val.shape)\n",
    "print('Y_test shape:', Y_test.shape)\n",
    "\n",
    "# Initialize model and optimizers\n",
    "model = Model(dropout=dropout, num_class=2)\n",
    "model.to(device)\n",
    "optimizer1 = optim.SGD(model.parameters(), lr=lr/5, weight_decay=decay, momentum=0.9, nesterov=True)\n",
    "optimizer2 = optim.SGD(model.parameters(), lr=lr, weight_decay=decay, momentum=0.9, nesterov=True)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "best_val_acc = 0\n",
    "best_model_path = f'outputs/model_fold{kfold_index}.pth'\n",
    "train_losses = []\n",
    "val_accs = []\n",
    "\n",
    "# idx_batch: 随机打乱训练集样本的索引，用于小批量训练。\n",
    "# num_batch, pre_num_batch: 计算每轮训练的批量数（分别用于微调和预训练）。\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    idx_batch = np.random.permutation(int(X_train.shape[0]))\n",
    "    num_batch = X_train.shape[0] // batch_size\n",
    "    pre_num_batch = X_train.shape[0] // pre_batch\n",
    "    loss_train = 0.0\n",
    "\n",
    "    if epoch <= pre_epo:\n",
    "        # Pre-training\n",
    "        for bn in range(pre_num_batch):\n",
    "            batch = idx_batch[bn * pre_batch: (bn + 1) * pre_batch] if bn < pre_num_batch - 1 else idx_batch[bn * pre_batch:]\n",
    "            \n",
    "            train_data_batch = X_train[batch]\n",
    "            train_data_batch_dev = torch.from_numpy(train_data_batch).float().to(device)\n",
    "\n",
    "            # 前向传播\n",
    "            semi_loss = model(train_data_batch_dev, pre=True)\n",
    "            loss = sum(semi_loss)\n",
    "\n",
    "            # 反向传播\n",
    "            # 梯度清零：清除旧梯度以避免累积。\n",
    "            # 计算梯度：loss.backward() 会计算每个模型参数对损失值的影响程度。\n",
    "            # 梯度裁剪：限制梯度大小以防止训练不稳定（例如梯度爆炸问题）。\n",
    "            # 更新参数：optimizer1.step() 使用较小学习率（lr/5）的 SGD 算法调整模型权重。\n",
    "            optimizer1.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer1.step()\n",
    "            loss_train += loss.item()\n",
    "        loss_train /= pre_num_batch # 平均损失\n",
    "        # 输出平均预训练损失和图稀疏度（116×116 邻接矩阵中非零连接的比例）。\n",
    "        print(f'Epoch {epoch}, Pre-training loss: {loss_train:.4f}, Sparse rate: {(model.sigcnn.get_w_data() != 0).int().sum() / (116*116):.4f}')\n",
    "    \n",
    "    else:\n",
    "        # Fine-tuning\n",
    "        mini_net = nn.Sequential(model.sigcnn)\n",
    "        for bn in range(num_batch):\n",
    "            batch = idx_batch[bn * batch_size: (bn + 1) * batch_size] if bn < num_batch - 1 else idx_batch[bn * batch_size:]\n",
    "            train_data_batch = X_train[batch]\n",
    "            train_label_batch = Y_train[batch]\n",
    "            train_data_batch_dev = torch.from_numpy(train_data_batch).float().to(device)\n",
    "            train_label_batch_dev = torch.from_numpy(train_label_batch).long().to(device)\n",
    "\n",
    "            # 生成图结构\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                train_data_batch_dev, _ = mini_net(train_data_batch_dev)\n",
    "            model.train()\n",
    "            outputs = model(train_data_batch_dev)\n",
    "            loss = loss_fn(outputs, train_label_batch_dev)\n",
    "            optimizer2.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer2.step()\n",
    "            loss_train += loss.item()\n",
    "        loss_train /= num_batch\n",
    "        train_losses.append(loss_train)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_data_dev = torch.from_numpy(X_val).float().to(device)\n",
    "            val_label_dev = torch.from_numpy(Y_val).long().to(device)\n",
    "            val_data_dev, _ = mini_net(val_data_dev)\n",
    "            outputs = model(val_data_dev)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            val_acc = metrics.accuracy_score(preds.cpu(), Y_val)\n",
    "            val_accs.append(val_acc)\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch}, Train loss: {loss_train:.4f}, Val acc: {val_acc:.4f}')\n",
    "\n",
    "# Test\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_data_dev = torch.from_numpy(X_test).float().to(device)\n",
    "    test_data_dev, _ = mini_net(test_data_dev)\n",
    "    outputs = model(test_data_dev)\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    acc, sen, spec, auc = confusion(Y_test, preds.cpu().numpy())\n",
    "    print(f'Test acc: {acc:.4f}, AUC: {auc:.4f}, Sensitivity: {sen:.4f}, Specificity: {spec:.4f}')\n",
    "\n",
    "# Save results\n",
    "result.append(acc)\n",
    "result_auc.append(auc)\n",
    "result_sen.append(sen)\n",
    "result_spec.append(spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Visualize Training Progress\n",
    "Plot training loss and validation accuracy to monitor convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(pre_epo + 1, epochs + 1), train_losses, 'b-o', label='Train Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(pre_epo + 1, epochs + 1), val_accs, 'r-o', label='Val Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/train_val_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Visualize Graph Structure\n",
    "Extract and save the learned adjacency matrix for visualization in BrainNetViewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency matrix saved to outputs/w_data.txt for BrainNetViewer\n"
     ]
    }
   ],
   "source": [
    "w_data = model.sigcnn.get_w_data().cpu().numpy()\n",
    "np.savetxt('outputs/w_data.txt', w_data)\n",
    "print('Adjacency matrix saved to outputs/w_data.txt for BrainNetViewer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Full Experiment (5 Runs × 5 Folds)\n",
    "Run the full experiment to match the paper's evaluation (5 runs of 5-fold cross-validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 0, Fold 1, Epoch 1, Pre-training loss: 12.9906, Sparse rate: 0.7459\n",
      "Seed 0, Fold 1, Epoch 2, Pre-training loss: 12.9425, Sparse rate: 0.7459\n",
      "Seed 0, Fold 1, Epoch 3, Pre-training loss: 12.8806, Sparse rate: 0.7459\n",
      "Seed 0, Fold 1, Epoch 4, Pre-training loss: 12.8269, Sparse rate: 0.7459\n",
      "Seed 0, Fold 1, Epoch 5, Pre-training loss: 12.7833, Sparse rate: 0.7458\n",
      "Seed 0, Fold 1, Epoch 6, Pre-training loss: 12.7446, Sparse rate: 0.7453\n",
      "Seed 0, Fold 1, Epoch 7, Pre-training loss: 12.7069, Sparse rate: 0.7452\n",
      "Seed 0, Fold 1, Epoch 8, Pre-training loss: 12.6700, Sparse rate: 0.7447\n",
      "Seed 0, Fold 1, Epoch 9, Pre-training loss: 12.6376, Sparse rate: 0.7438\n",
      "Seed 0, Fold 1, Epoch 10, Pre-training loss: 12.6014, Sparse rate: 0.7433\n",
      "Seed 0, Fold 1, Epoch 20, Train loss: 0.6885, Val acc: 0.6377\n",
      "Seed 0, Fold 1, Epoch 30, Train loss: 0.6886, Val acc: 0.6377\n",
      "Seed 0, Fold 1, Epoch 40, Train loss: 0.6915, Val acc: 0.6377\n",
      "Seed 0, Fold 1, Epoch 50, Train loss: 0.6917, Val acc: 0.6377\n",
      "Seed 0, Fold 1, Epoch 60, Train loss: 0.6874, Val acc: 0.6377\n",
      "Seed 0, Fold 1, Test acc: 0.6163, AUC: 0.5000, Sensitivity: 0.0000, Specificity: 1.0000\n",
      "Seed 0, Fold 2, Epoch 1, Pre-training loss: 13.3037, Sparse rate: 0.7473\n",
      "Seed 0, Fold 2, Epoch 2, Pre-training loss: 13.1670, Sparse rate: 0.7473\n",
      "Seed 0, Fold 2, Epoch 3, Pre-training loss: 13.0233, Sparse rate: 0.7473\n",
      "Seed 0, Fold 2, Epoch 4, Pre-training loss: 12.9389, Sparse rate: 0.7468\n",
      "Seed 0, Fold 2, Epoch 5, Pre-training loss: 12.8646, Sparse rate: 0.7467\n",
      "Seed 0, Fold 2, Epoch 6, Pre-training loss: 12.8235, Sparse rate: 0.7467\n",
      "Seed 0, Fold 2, Epoch 7, Pre-training loss: 12.7913, Sparse rate: 0.7462\n",
      "Seed 0, Fold 2, Epoch 8, Pre-training loss: 12.7494, Sparse rate: 0.7456\n",
      "Seed 0, Fold 2, Epoch 9, Pre-training loss: 12.7228, Sparse rate: 0.7453\n",
      "Seed 0, Fold 2, Epoch 10, Pre-training loss: 12.6822, Sparse rate: 0.7449\n",
      "Seed 0, Fold 2, Epoch 20, Train loss: 0.6871, Val acc: 0.5652\n",
      "Seed 0, Fold 2, Epoch 30, Train loss: 0.6809, Val acc: 0.5652\n",
      "Seed 0, Fold 2, Epoch 40, Train loss: 0.6671, Val acc: 0.5652\n",
      "Seed 0, Fold 2, Epoch 50, Train loss: 0.6513, Val acc: 0.5652\n",
      "Seed 0, Fold 2, Epoch 60, Train loss: 0.6381, Val acc: 0.5797\n",
      "Seed 0, Fold 2, Test acc: 0.5698, AUC: 0.5214, Sensitivity: 0.1053, Specificity: 0.9375\n",
      "Seed 0, Fold 3, Epoch 1, Pre-training loss: 13.1028, Sparse rate: 0.7512\n",
      "Seed 0, Fold 3, Epoch 2, Pre-training loss: 13.0152, Sparse rate: 0.7510\n",
      "Seed 0, Fold 3, Epoch 3, Pre-training loss: 12.9252, Sparse rate: 0.7510\n",
      "Seed 0, Fold 3, Epoch 4, Pre-training loss: 12.8561, Sparse rate: 0.7506\n",
      "Seed 0, Fold 3, Epoch 5, Pre-training loss: 12.8095, Sparse rate: 0.7503\n",
      "Seed 0, Fold 3, Epoch 6, Pre-training loss: 12.7665, Sparse rate: 0.7503\n",
      "Seed 0, Fold 3, Epoch 7, Pre-training loss: 12.7286, Sparse rate: 0.7503\n",
      "Seed 0, Fold 3, Epoch 8, Pre-training loss: 12.6981, Sparse rate: 0.7501\n",
      "Seed 0, Fold 3, Epoch 9, Pre-training loss: 12.6634, Sparse rate: 0.7499\n",
      "Seed 0, Fold 3, Epoch 10, Pre-training loss: 12.6277, Sparse rate: 0.7493\n",
      "Seed 0, Fold 3, Epoch 20, Train loss: 0.6893, Val acc: 0.5942\n",
      "Seed 0, Fold 3, Epoch 30, Train loss: 0.6917, Val acc: 0.5942\n",
      "Seed 0, Fold 3, Epoch 40, Train loss: 0.6837, Val acc: 0.5942\n",
      "Seed 0, Fold 3, Epoch 50, Train loss: 0.6840, Val acc: 0.5942\n",
      "Seed 0, Fold 3, Epoch 60, Train loss: 0.6880, Val acc: 0.5942\n",
      "Seed 0, Fold 3, Test acc: 0.6118, AUC: 0.5000, Sensitivity: 0.0000, Specificity: 1.0000\n",
      "Seed 0, Fold 4, Epoch 1, Pre-training loss: 12.9797, Sparse rate: 0.7476\n",
      "Seed 0, Fold 4, Epoch 2, Pre-training loss: 12.9301, Sparse rate: 0.7476\n",
      "Seed 0, Fold 4, Epoch 3, Pre-training loss: 12.8795, Sparse rate: 0.7476\n",
      "Seed 0, Fold 4, Epoch 4, Pre-training loss: 12.8226, Sparse rate: 0.7473\n",
      "Seed 0, Fold 4, Epoch 5, Pre-training loss: 12.7805, Sparse rate: 0.7470\n",
      "Seed 0, Fold 4, Epoch 6, Pre-training loss: 12.7444, Sparse rate: 0.7469\n",
      "Seed 0, Fold 4, Epoch 7, Pre-training loss: 12.7035, Sparse rate: 0.7464\n",
      "Seed 0, Fold 4, Epoch 8, Pre-training loss: 12.6721, Sparse rate: 0.7458\n",
      "Seed 0, Fold 4, Epoch 9, Pre-training loss: 12.6352, Sparse rate: 0.7457\n",
      "Seed 0, Fold 4, Epoch 10, Pre-training loss: 12.6008, Sparse rate: 0.7452\n",
      "Seed 0, Fold 4, Epoch 20, Train loss: 0.6781, Val acc: 0.5362\n",
      "Seed 0, Fold 4, Epoch 30, Train loss: 0.6710, Val acc: 0.5362\n",
      "Seed 0, Fold 4, Epoch 40, Train loss: 0.6739, Val acc: 0.5362\n",
      "Seed 0, Fold 4, Epoch 50, Train loss: 0.6690, Val acc: 0.5362\n",
      "Seed 0, Fold 4, Epoch 60, Train loss: 0.6672, Val acc: 0.5362\n",
      "Seed 0, Fold 4, Test acc: 0.5412, AUC: 0.5000, Sensitivity: 0.0000, Specificity: 1.0000\n",
      "Seed 0, Fold 5, Epoch 1, Pre-training loss: 13.1477, Sparse rate: 0.7566\n",
      "Seed 0, Fold 5, Epoch 2, Pre-training loss: 13.0458, Sparse rate: 0.7566\n",
      "Seed 0, Fold 5, Epoch 3, Pre-training loss: 12.9325, Sparse rate: 0.7566\n",
      "Seed 0, Fold 5, Epoch 4, Pre-training loss: 12.8626, Sparse rate: 0.7566\n",
      "Seed 0, Fold 5, Epoch 5, Pre-training loss: 12.8061, Sparse rate: 0.7565\n",
      "Seed 0, Fold 5, Epoch 6, Pre-training loss: 12.7585, Sparse rate: 0.7565\n",
      "Seed 0, Fold 5, Epoch 7, Pre-training loss: 12.7120, Sparse rate: 0.7562\n",
      "Seed 0, Fold 5, Epoch 8, Pre-training loss: 12.6776, Sparse rate: 0.7559\n",
      "Seed 0, Fold 5, Epoch 9, Pre-training loss: 12.6419, Sparse rate: 0.7557\n",
      "Seed 0, Fold 5, Epoch 10, Pre-training loss: 12.6086, Sparse rate: 0.7557\n",
      "Seed 0, Fold 5, Epoch 20, Train loss: 0.6884, Val acc: 0.6087\n",
      "Seed 0, Fold 5, Epoch 30, Train loss: 0.6880, Val acc: 0.6087\n",
      "Seed 0, Fold 5, Epoch 40, Train loss: 0.6877, Val acc: 0.6087\n",
      "Seed 0, Fold 5, Epoch 50, Train loss: 0.6812, Val acc: 0.6087\n",
      "Seed 0, Fold 5, Epoch 60, Train loss: 0.6842, Val acc: 0.6087\n",
      "Seed 0, Fold 5, Test acc: 0.5529, AUC: 0.5000, Sensitivity: 0.0000, Specificity: 1.0000\n",
      "Seed 1, Fold 1, Epoch 1, Pre-training loss: 12.9693, Sparse rate: 0.7560\n",
      "Seed 1, Fold 1, Epoch 2, Pre-training loss: 12.8953, Sparse rate: 0.7560\n",
      "Seed 1, Fold 1, Epoch 3, Pre-training loss: 12.8283, Sparse rate: 0.7557\n",
      "Seed 1, Fold 1, Epoch 4, Pre-training loss: 12.7774, Sparse rate: 0.7554\n",
      "Seed 1, Fold 1, Epoch 5, Pre-training loss: 12.7389, Sparse rate: 0.7553\n",
      "Seed 1, Fold 1, Epoch 6, Pre-training loss: 12.7058, Sparse rate: 0.7547\n",
      "Seed 1, Fold 1, Epoch 7, Pre-training loss: 12.6719, Sparse rate: 0.7539\n",
      "Seed 1, Fold 1, Epoch 8, Pre-training loss: 12.6378, Sparse rate: 0.7537\n",
      "Seed 1, Fold 1, Epoch 9, Pre-training loss: 12.6032, Sparse rate: 0.7534\n",
      "Seed 1, Fold 1, Epoch 10, Pre-training loss: 12.5710, Sparse rate: 0.7533\n",
      "Seed 1, Fold 1, Epoch 20, Train loss: 0.6785, Val acc: 0.5362\n",
      "Seed 1, Fold 1, Epoch 30, Train loss: 0.6723, Val acc: 0.5362\n",
      "Seed 1, Fold 1, Epoch 40, Train loss: 0.6811, Val acc: 0.5362\n",
      "Seed 1, Fold 1, Epoch 50, Train loss: 0.6712, Val acc: 0.5362\n",
      "Seed 1, Fold 1, Epoch 60, Train loss: 0.6760, Val acc: 0.5362\n",
      "Seed 1, Fold 1, Test acc: 0.5116, AUC: 0.5000, Sensitivity: 0.0000, Specificity: 1.0000\n",
      "Seed 1, Fold 2, Epoch 1, Pre-training loss: 13.0949, Sparse rate: 0.7467\n",
      "Seed 1, Fold 2, Epoch 2, Pre-training loss: 13.0120, Sparse rate: 0.7465\n",
      "Seed 1, Fold 2, Epoch 3, Pre-training loss: 12.9159, Sparse rate: 0.7465\n",
      "Seed 1, Fold 2, Epoch 4, Pre-training loss: 12.8436, Sparse rate: 0.7462\n",
      "Seed 1, Fold 2, Epoch 5, Pre-training loss: 12.7869, Sparse rate: 0.7458\n",
      "Seed 1, Fold 2, Epoch 6, Pre-training loss: 12.7420, Sparse rate: 0.7456\n",
      "Seed 1, Fold 2, Epoch 7, Pre-training loss: 12.7021, Sparse rate: 0.7450\n",
      "Seed 1, Fold 2, Epoch 8, Pre-training loss: 12.6595, Sparse rate: 0.7447\n",
      "Seed 1, Fold 2, Epoch 9, Pre-training loss: 12.6230, Sparse rate: 0.7441\n",
      "Seed 1, Fold 2, Epoch 10, Pre-training loss: 12.5971, Sparse rate: 0.7438\n",
      "Seed 1, Fold 2, Epoch 20, Train loss: 0.6762, Val acc: 0.5797\n",
      "Seed 1, Fold 2, Epoch 30, Train loss: 0.6905, Val acc: 0.5797\n",
      "Seed 1, Fold 2, Epoch 40, Train loss: 0.6764, Val acc: 0.5797\n",
      "Seed 1, Fold 2, Epoch 50, Train loss: 0.6882, Val acc: 0.5797\n",
      "Seed 1, Fold 2, Epoch 60, Train loss: 0.6822, Val acc: 0.5797\n",
      "Seed 1, Fold 2, Test acc: 0.5814, AUC: 0.5000, Sensitivity: 0.0000, Specificity: 1.0000\n",
      "Seed 1, Fold 3, Epoch 1, Pre-training loss: 13.1134, Sparse rate: 0.7515\n",
      "Seed 1, Fold 3, Epoch 2, Pre-training loss: 12.9912, Sparse rate: 0.7515\n",
      "Seed 1, Fold 3, Epoch 3, Pre-training loss: 12.8762, Sparse rate: 0.7511\n",
      "Seed 1, Fold 3, Epoch 4, Pre-training loss: 12.8013, Sparse rate: 0.7511\n",
      "Seed 1, Fold 3, Epoch 5, Pre-training loss: 12.7573, Sparse rate: 0.7511\n",
      "Seed 1, Fold 3, Epoch 6, Pre-training loss: 12.7108, Sparse rate: 0.7510\n",
      "Seed 1, Fold 3, Epoch 7, Pre-training loss: 12.6712, Sparse rate: 0.7507\n",
      "Seed 1, Fold 3, Epoch 8, Pre-training loss: 12.6356, Sparse rate: 0.7507\n",
      "Seed 1, Fold 3, Epoch 9, Pre-training loss: 12.6027, Sparse rate: 0.7502\n",
      "Seed 1, Fold 3, Epoch 10, Pre-training loss: 12.5696, Sparse rate: 0.7499\n",
      "Seed 1, Fold 3, Epoch 20, Train loss: 0.6878, Val acc: 0.6957\n",
      "Seed 1, Fold 3, Epoch 30, Train loss: 0.6870, Val acc: 0.6957\n",
      "Seed 1, Fold 3, Epoch 40, Train loss: 0.6894, Val acc: 0.6957\n",
      "Seed 1, Fold 3, Epoch 50, Train loss: 0.6890, Val acc: 0.6957\n",
      "Seed 1, Fold 3, Epoch 60, Train loss: 0.6880, Val acc: 0.6957\n",
      "Seed 1, Fold 3, Test acc: 0.5882, AUC: 0.5000, Sensitivity: 0.0000, Specificity: 1.0000\n",
      "Seed 1, Fold 4, Epoch 1, Pre-training loss: 13.2498, Sparse rate: 0.7496\n",
      "Seed 1, Fold 4, Epoch 2, Pre-training loss: 13.1350, Sparse rate: 0.7496\n",
      "Seed 1, Fold 4, Epoch 3, Pre-training loss: 13.0077, Sparse rate: 0.7496\n",
      "Seed 1, Fold 4, Epoch 4, Pre-training loss: 12.8948, Sparse rate: 0.7493\n",
      "Seed 1, Fold 4, Epoch 5, Pre-training loss: 12.8159, Sparse rate: 0.7493\n",
      "Seed 1, Fold 4, Epoch 6, Pre-training loss: 12.7674, Sparse rate: 0.7489\n",
      "Seed 1, Fold 4, Epoch 7, Pre-training loss: 12.7248, Sparse rate: 0.7486\n",
      "Seed 1, Fold 4, Epoch 8, Pre-training loss: 12.6896, Sparse rate: 0.7480\n",
      "Seed 1, Fold 4, Epoch 9, Pre-training loss: 12.6546, Sparse rate: 0.7473\n",
      "Seed 1, Fold 4, Epoch 10, Pre-training loss: 12.6195, Sparse rate: 0.7467\n",
      "Seed 1, Fold 4, Epoch 20, Train loss: 0.6851, Val acc: 0.5942\n",
      "Seed 1, Fold 4, Epoch 30, Train loss: 0.6815, Val acc: 0.5942\n",
      "Seed 1, Fold 4, Epoch 40, Train loss: 0.6890, Val acc: 0.5942\n",
      "Seed 1, Fold 4, Epoch 50, Train loss: 0.6891, Val acc: 0.5942\n",
      "Seed 1, Fold 4, Epoch 60, Train loss: 0.6823, Val acc: 0.5942\n",
      "Seed 1, Fold 4, Test acc: 0.6353, AUC: 0.5000, Sensitivity: 0.0000, Specificity: 1.0000\n",
      "Seed 1, Fold 5, Epoch 1, Pre-training loss: 13.3286, Sparse rate: 0.7542\n",
      "Seed 1, Fold 5, Epoch 2, Pre-training loss: 13.2145, Sparse rate: 0.7542\n",
      "Seed 1, Fold 5, Epoch 3, Pre-training loss: 13.0901, Sparse rate: 0.7542\n",
      "Seed 1, Fold 5, Epoch 4, Pre-training loss: 12.9848, Sparse rate: 0.7540\n",
      "Seed 1, Fold 5, Epoch 5, Pre-training loss: 12.9020, Sparse rate: 0.7540\n",
      "Seed 1, Fold 5, Epoch 6, Pre-training loss: 12.8411, Sparse rate: 0.7537\n",
      "Seed 1, Fold 5, Epoch 7, Pre-training loss: 12.7928, Sparse rate: 0.7531\n",
      "Seed 1, Fold 5, Epoch 8, Pre-training loss: 12.7445, Sparse rate: 0.7528\n",
      "Seed 1, Fold 5, Epoch 9, Pre-training loss: 12.7108, Sparse rate: 0.7525\n",
      "Seed 1, Fold 5, Epoch 10, Pre-training loss: 12.6739, Sparse rate: 0.7518\n",
      "Seed 1, Fold 5, Epoch 20, Train loss: 0.6879, Val acc: 0.6232\n",
      "Seed 1, Fold 5, Epoch 30, Train loss: 0.6881, Val acc: 0.6232\n",
      "Seed 1, Fold 5, Epoch 40, Train loss: 0.6895, Val acc: 0.6232\n",
      "Seed 1, Fold 5, Epoch 50, Train loss: 0.6901, Val acc: 0.6232\n",
      "Seed 1, Fold 5, Epoch 60, Train loss: 0.6780, Val acc: 0.6232\n",
      "Seed 1, Fold 5, Test acc: 0.5647, AUC: 0.5000, Sensitivity: 0.0000, Specificity: 1.0000\n",
      "Seed 2, Fold 1, Epoch 1, Pre-training loss: 13.2509, Sparse rate: 0.7469\n",
      "Seed 2, Fold 1, Epoch 2, Pre-training loss: 13.1387, Sparse rate: 0.7469\n",
      "Seed 2, Fold 1, Epoch 3, Pre-training loss: 13.0105, Sparse rate: 0.7466\n",
      "Seed 2, Fold 1, Epoch 4, Pre-training loss: 12.8969, Sparse rate: 0.7466\n",
      "Seed 2, Fold 1, Epoch 5, Pre-training loss: 12.8209, Sparse rate: 0.7466\n",
      "Seed 2, Fold 1, Epoch 6, Pre-training loss: 12.7656, Sparse rate: 0.7463\n",
      "Seed 2, Fold 1, Epoch 7, Pre-training loss: 12.7212, Sparse rate: 0.7461\n",
      "Seed 2, Fold 1, Epoch 8, Pre-training loss: 12.6883, Sparse rate: 0.7457\n",
      "Seed 2, Fold 1, Epoch 9, Pre-training loss: 12.6541, Sparse rate: 0.7451\n",
      "Seed 2, Fold 1, Epoch 10, Pre-training loss: 12.6184, Sparse rate: 0.7449\n",
      "Seed 2, Fold 1, Epoch 20, Train loss: 0.6881, Val acc: 0.6522\n",
      "Seed 2, Fold 1, Epoch 30, Train loss: 0.6888, Val acc: 0.6522\n",
      "Seed 2, Fold 1, Epoch 40, Train loss: 0.6891, Val acc: 0.6522\n",
      "Seed 2, Fold 1, Epoch 50, Train loss: 0.6870, Val acc: 0.6522\n",
      "Seed 2, Fold 1, Epoch 60, Train loss: 0.6862, Val acc: 0.6522\n",
      "Seed 2, Fold 1, Test acc: 0.5930, AUC: 0.5000, Sensitivity: 0.0000, Specificity: 1.0000\n",
      "Seed 2, Fold 2, Epoch 1, Pre-training loss: 13.0374, Sparse rate: 0.7473\n",
      "Seed 2, Fold 2, Epoch 2, Pre-training loss: 12.9643, Sparse rate: 0.7473\n",
      "Seed 2, Fold 2, Epoch 3, Pre-training loss: 12.8729, Sparse rate: 0.7470\n",
      "Seed 2, Fold 2, Epoch 4, Pre-training loss: 12.8219, Sparse rate: 0.7468\n",
      "Seed 2, Fold 2, Epoch 5, Pre-training loss: 12.7692, Sparse rate: 0.7468\n",
      "Seed 2, Fold 2, Epoch 6, Pre-training loss: 12.7320, Sparse rate: 0.7467\n",
      "Seed 2, Fold 2, Epoch 7, Pre-training loss: 12.6998, Sparse rate: 0.7459\n",
      "Seed 2, Fold 2, Epoch 8, Pre-training loss: 12.6654, Sparse rate: 0.7456\n",
      "Seed 2, Fold 2, Epoch 9, Pre-training loss: 12.6292, Sparse rate: 0.7453\n",
      "Seed 2, Fold 2, Epoch 10, Pre-training loss: 12.5937, Sparse rate: 0.7450\n",
      "Seed 2, Fold 2, Epoch 20, Train loss: 0.6790, Val acc: 0.4783\n",
      "Seed 2, Fold 2, Epoch 30, Train loss: 0.6916, Val acc: 0.4783\n",
      "Seed 2, Fold 2, Epoch 40, Train loss: 0.6687, Val acc: 0.4783\n",
      "Seed 2, Fold 2, Epoch 50, Train loss: 0.6798, Val acc: 0.4783\n",
      "Seed 2, Fold 2, Epoch 60, Train loss: 0.6674, Val acc: 0.4783\n",
      "Seed 2, Fold 2, Test acc: 0.5814, AUC: 0.5000, Sensitivity: 0.0000, Specificity: 1.0000\n",
      "Seed 2, Fold 3, Epoch 1, Pre-training loss: 12.9813, Sparse rate: 0.7409\n",
      "Seed 2, Fold 3, Epoch 2, Pre-training loss: 12.9172, Sparse rate: 0.7407\n",
      "Seed 2, Fold 3, Epoch 3, Pre-training loss: 12.8603, Sparse rate: 0.7406\n",
      "Seed 2, Fold 3, Epoch 4, Pre-training loss: 12.8225, Sparse rate: 0.7403\n",
      "Seed 2, Fold 3, Epoch 5, Pre-training loss: 12.7815, Sparse rate: 0.7401\n",
      "Seed 2, Fold 3, Epoch 6, Pre-training loss: 12.7379, Sparse rate: 0.7398\n",
      "Seed 2, Fold 3, Epoch 7, Pre-training loss: 12.7089, Sparse rate: 0.7398\n",
      "Seed 2, Fold 3, Epoch 8, Pre-training loss: 12.6732, Sparse rate: 0.7395\n",
      "Seed 2, Fold 3, Epoch 9, Pre-training loss: 12.6429, Sparse rate: 0.7393\n",
      "Seed 2, Fold 3, Epoch 10, Pre-training loss: 12.6083, Sparse rate: 0.7387\n",
      "Seed 2, Fold 3, Epoch 20, Train loss: 0.6890, Val acc: 0.5362\n",
      "Seed 2, Fold 3, Epoch 30, Train loss: 0.6884, Val acc: 0.5362\n",
      "Seed 2, Fold 3, Epoch 40, Train loss: 0.6789, Val acc: 0.5362\n",
      "Seed 2, Fold 3, Epoch 50, Train loss: 0.6823, Val acc: 0.5362\n",
      "Seed 2, Fold 3, Epoch 60, Train loss: 0.6828, Val acc: 0.5362\n",
      "Seed 2, Fold 3, Test acc: 0.6118, AUC: 0.5000, Sensitivity: 0.0000, Specificity: 1.0000\n",
      "Seed 2, Fold 4, Epoch 1, Pre-training loss: 13.0980, Sparse rate: 0.7436\n",
      "Seed 2, Fold 4, Epoch 2, Pre-training loss: 13.0059, Sparse rate: 0.7435\n",
      "Seed 2, Fold 4, Epoch 3, Pre-training loss: 12.9208, Sparse rate: 0.7435\n",
      "Seed 2, Fold 4, Epoch 4, Pre-training loss: 12.8598, Sparse rate: 0.7433\n",
      "Seed 2, Fold 4, Epoch 5, Pre-training loss: 12.8090, Sparse rate: 0.7433\n",
      "Seed 2, Fold 4, Epoch 6, Pre-training loss: 12.7724, Sparse rate: 0.7432\n",
      "Seed 2, Fold 4, Epoch 7, Pre-training loss: 12.7357, Sparse rate: 0.7427\n",
      "Seed 2, Fold 4, Epoch 8, Pre-training loss: 12.6993, Sparse rate: 0.7424\n",
      "Seed 2, Fold 4, Epoch 9, Pre-training loss: 12.6608, Sparse rate: 0.7421\n",
      "Seed 2, Fold 4, Epoch 10, Pre-training loss: 12.6272, Sparse rate: 0.7417\n",
      "Seed 2, Fold 4, Epoch 20, Train loss: 0.6805, Val acc: 0.5362\n",
      "Seed 2, Fold 4, Epoch 30, Train loss: 0.6687, Val acc: 0.5362\n",
      "Seed 2, Fold 4, Epoch 40, Train loss: 0.6747, Val acc: 0.5362\n",
      "Seed 2, Fold 4, Epoch 50, Train loss: 0.6723, Val acc: 0.5362\n",
      "Seed 2, Fold 4, Epoch 60, Train loss: 0.6634, Val acc: 0.5362\n",
      "Seed 2, Fold 4, Test acc: 0.5059, AUC: 0.5000, Sensitivity: 0.0000, Specificity: 1.0000\n",
      "Seed 2, Fold 5, Epoch 1, Pre-training loss: 13.1764, Sparse rate: 0.7482\n",
      "Seed 2, Fold 5, Epoch 2, Pre-training loss: 13.0610, Sparse rate: 0.7482\n",
      "Seed 2, Fold 5, Epoch 3, Pre-training loss: 12.9423, Sparse rate: 0.7481\n",
      "Seed 2, Fold 5, Epoch 4, Pre-training loss: 12.8590, Sparse rate: 0.7479\n",
      "Seed 2, Fold 5, Epoch 5, Pre-training loss: 12.7963, Sparse rate: 0.7478\n",
      "Seed 2, Fold 5, Epoch 6, Pre-training loss: 12.7575, Sparse rate: 0.7476\n",
      "Seed 2, Fold 5, Epoch 7, Pre-training loss: 12.7096, Sparse rate: 0.7472\n",
      "Seed 2, Fold 5, Epoch 8, Pre-training loss: 12.6677, Sparse rate: 0.7467\n",
      "Seed 2, Fold 5, Epoch 9, Pre-training loss: 12.6390, Sparse rate: 0.7463\n",
      "Seed 2, Fold 5, Epoch 10, Pre-training loss: 12.6031, Sparse rate: 0.7460\n",
      "Seed 2, Fold 5, Epoch 20, Train loss: 0.6802, Val acc: 0.4348\n",
      "Seed 2, Fold 5, Epoch 30, Train loss: 0.6782, Val acc: 0.4348\n",
      "Seed 2, Fold 5, Epoch 40, Train loss: 0.6751, Val acc: 0.4348\n",
      "Seed 2, Fold 5, Epoch 50, Train loss: 0.6729, Val acc: 0.4348\n",
      "Seed 2, Fold 5, Epoch 60, Train loss: 0.6758, Val acc: 0.4348\n",
      "Seed 2, Fold 5, Test acc: 0.5882, AUC: 0.5000, Sensitivity: 0.0000, Specificity: 1.0000\n",
      "Seed 3, Fold 1, Epoch 1, Pre-training loss: 13.2261, Sparse rate: 0.7507\n",
      "Seed 3, Fold 1, Epoch 2, Pre-training loss: 13.0879, Sparse rate: 0.7506\n",
      "Seed 3, Fold 1, Epoch 3, Pre-training loss: 12.9640, Sparse rate: 0.7506\n",
      "Seed 3, Fold 1, Epoch 4, Pre-training loss: 12.8787, Sparse rate: 0.7503\n",
      "Seed 3, Fold 1, Epoch 5, Pre-training loss: 12.8143, Sparse rate: 0.7501\n",
      "Seed 3, Fold 1, Epoch 6, Pre-training loss: 12.7672, Sparse rate: 0.7496\n",
      "Seed 3, Fold 1, Epoch 7, Pre-training loss: 12.7269, Sparse rate: 0.7491\n",
      "Seed 3, Fold 1, Epoch 8, Pre-training loss: 12.6889, Sparse rate: 0.7487\n",
      "Seed 3, Fold 1, Epoch 9, Pre-training loss: 12.6521, Sparse rate: 0.7481\n",
      "Seed 3, Fold 1, Epoch 10, Pre-training loss: 12.6164, Sparse rate: 0.7478\n",
      "Seed 3, Fold 1, Epoch 20, Train loss: 0.6870, Val acc: 0.5797\n",
      "Seed 3, Fold 1, Epoch 30, Train loss: 0.6823, Val acc: 0.5797\n",
      "Seed 3, Fold 1, Epoch 40, Train loss: 0.6859, Val acc: 0.5797\n",
      "Seed 3, Fold 1, Epoch 50, Train loss: 0.6818, Val acc: 0.5797\n",
      "Seed 3, Fold 1, Epoch 60, Train loss: 0.6881, Val acc: 0.5797\n",
      "Seed 3, Fold 1, Test acc: 0.6047, AUC: 0.5000, Sensitivity: 0.0000, Specificity: 1.0000\n",
      "Seed 3, Fold 2, Epoch 1, Pre-training loss: 13.1888, Sparse rate: 0.7453\n",
      "Seed 3, Fold 2, Epoch 2, Pre-training loss: 13.1059, Sparse rate: 0.7452\n",
      "Seed 3, Fold 2, Epoch 3, Pre-training loss: 13.0028, Sparse rate: 0.7452\n",
      "Seed 3, Fold 2, Epoch 4, Pre-training loss: 12.9210, Sparse rate: 0.7450\n",
      "Seed 3, Fold 2, Epoch 5, Pre-training loss: 12.8533, Sparse rate: 0.7446\n",
      "Seed 3, Fold 2, Epoch 6, Pre-training loss: 12.8082, Sparse rate: 0.7446\n",
      "Seed 3, Fold 2, Epoch 7, Pre-training loss: 12.7689, Sparse rate: 0.7444\n",
      "Seed 3, Fold 2, Epoch 8, Pre-training loss: 12.7302, Sparse rate: 0.7441\n",
      "Seed 3, Fold 2, Epoch 9, Pre-training loss: 12.6932, Sparse rate: 0.7437\n",
      "Seed 3, Fold 2, Epoch 10, Pre-training loss: 12.6556, Sparse rate: 0.7435\n",
      "Seed 3, Fold 2, Epoch 20, Train loss: 0.6897, Val acc: 0.5942\n",
      "Seed 3, Fold 2, Epoch 30, Train loss: 0.6874, Val acc: 0.5942\n",
      "Seed 3, Fold 2, Epoch 40, Train loss: 0.6917, Val acc: 0.5942\n",
      "Seed 3, Fold 2, Epoch 50, Train loss: 0.6859, Val acc: 0.5942\n",
      "Seed 3, Fold 2, Epoch 60, Train loss: 0.6847, Val acc: 0.5942\n",
      "Seed 3, Fold 2, Test acc: 0.6279, AUC: 0.5000, Sensitivity: 0.0000, Specificity: 1.0000\n",
      "Seed 3, Fold 3, Epoch 1, Pre-training loss: 13.2282, Sparse rate: 0.7504\n",
      "Seed 3, Fold 3, Epoch 2, Pre-training loss: 13.1427, Sparse rate: 0.7504\n",
      "Seed 3, Fold 3, Epoch 3, Pre-training loss: 13.0451, Sparse rate: 0.7504\n",
      "Seed 3, Fold 3, Epoch 4, Pre-training loss: 12.9722, Sparse rate: 0.7501\n",
      "Seed 3, Fold 3, Epoch 5, Pre-training loss: 12.9002, Sparse rate: 0.7501\n",
      "Seed 3, Fold 3, Epoch 6, Pre-training loss: 12.8446, Sparse rate: 0.7501\n",
      "Seed 3, Fold 3, Epoch 7, Pre-training loss: 12.8062, Sparse rate: 0.7501\n",
      "Seed 3, Fold 3, Epoch 8, Pre-training loss: 12.7675, Sparse rate: 0.7500\n",
      "Seed 3, Fold 3, Epoch 9, Pre-training loss: 12.7270, Sparse rate: 0.7499\n",
      "Seed 3, Fold 3, Epoch 10, Pre-training loss: 12.6932, Sparse rate: 0.7493\n",
      "Seed 3, Fold 3, Epoch 20, Train loss: 0.6875, Val acc: 0.6232\n",
      "Seed 3, Fold 3, Epoch 30, Train loss: 0.6809, Val acc: 0.6232\n",
      "Seed 3, Fold 3, Epoch 40, Train loss: 0.6954, Val acc: 0.6232\n",
      "Seed 3, Fold 3, Epoch 50, Train loss: 0.6905, Val acc: 0.6232\n",
      "Seed 3, Fold 3, Epoch 60, Train loss: 0.6894, Val acc: 0.6232\n",
      "Seed 3, Fold 3, Test acc: 0.6000, AUC: 0.5000, Sensitivity: 0.0000, Specificity: 1.0000\n",
      "Seed 3, Fold 4, Epoch 1, Pre-training loss: 13.3079, Sparse rate: 0.7444\n",
      "Seed 3, Fold 4, Epoch 2, Pre-training loss: 13.1774, Sparse rate: 0.7444\n",
      "Seed 3, Fold 4, Epoch 3, Pre-training loss: 13.0422, Sparse rate: 0.7443\n",
      "Seed 3, Fold 4, Epoch 4, Pre-training loss: 12.9433, Sparse rate: 0.7441\n",
      "Seed 3, Fold 4, Epoch 5, Pre-training loss: 12.8685, Sparse rate: 0.7438\n",
      "Seed 3, Fold 4, Epoch 6, Pre-training loss: 12.8168, Sparse rate: 0.7437\n",
      "Seed 3, Fold 4, Epoch 7, Pre-training loss: 12.7770, Sparse rate: 0.7434\n",
      "Seed 3, Fold 4, Epoch 8, Pre-training loss: 12.7308, Sparse rate: 0.7429\n",
      "Seed 3, Fold 4, Epoch 9, Pre-training loss: 12.7035, Sparse rate: 0.7425\n",
      "Seed 3, Fold 4, Epoch 10, Pre-training loss: 12.6636, Sparse rate: 0.7423\n",
      "Seed 3, Fold 4, Epoch 20, Train loss: 0.6885, Val acc: 0.6667\n",
      "Seed 3, Fold 4, Epoch 30, Train loss: 0.6793, Val acc: 0.6667\n",
      "Seed 3, Fold 4, Epoch 40, Train loss: 0.6842, Val acc: 0.6667\n",
      "Seed 3, Fold 4, Epoch 50, Train loss: 0.6765, Val acc: 0.6667\n",
      "Seed 3, Fold 4, Epoch 60, Train loss: 0.6755, Val acc: 0.6667\n",
      "Seed 3, Fold 4, Test acc: 0.4706, AUC: 0.5000, Sensitivity: 0.0000, Specificity: 1.0000\n",
      "Seed 3, Fold 5, Epoch 1, Pre-training loss: 13.1093, Sparse rate: 0.7497\n",
      "Seed 3, Fold 5, Epoch 2, Pre-training loss: 13.0395, Sparse rate: 0.7497\n",
      "Seed 3, Fold 5, Epoch 3, Pre-training loss: 12.9773, Sparse rate: 0.7497\n",
      "Seed 3, Fold 5, Epoch 4, Pre-training loss: 12.9144, Sparse rate: 0.7496\n",
      "Seed 3, Fold 5, Epoch 5, Pre-training loss: 12.8401, Sparse rate: 0.7494\n",
      "Seed 3, Fold 5, Epoch 6, Pre-training loss: 12.7926, Sparse rate: 0.7493\n",
      "Seed 3, Fold 5, Epoch 7, Pre-training loss: 12.7535, Sparse rate: 0.7493\n",
      "Seed 3, Fold 5, Epoch 8, Pre-training loss: 12.7102, Sparse rate: 0.7488\n",
      "Seed 3, Fold 5, Epoch 9, Pre-training loss: 12.6738, Sparse rate: 0.7484\n",
      "Seed 3, Fold 5, Epoch 10, Pre-training loss: 12.6368, Sparse rate: 0.7476\n",
      "Seed 3, Fold 5, Epoch 20, Train loss: 0.6861, Val acc: 0.5942\n",
      "Seed 3, Fold 5, Epoch 30, Train loss: 0.6835, Val acc: 0.5942\n",
      "Seed 3, Fold 5, Epoch 40, Train loss: 0.6815, Val acc: 0.5942\n",
      "Seed 3, Fold 5, Epoch 50, Train loss: 0.6848, Val acc: 0.5942\n",
      "Seed 3, Fold 5, Epoch 60, Train loss: 0.6848, Val acc: 0.5942\n",
      "Seed 3, Fold 5, Test acc: 0.5765, AUC: 0.5000, Sensitivity: 0.0000, Specificity: 1.0000\n",
      "Seed 4, Fold 1, Epoch 1, Pre-training loss: 13.2601, Sparse rate: 0.7449\n",
      "Seed 4, Fold 1, Epoch 2, Pre-training loss: 13.1452, Sparse rate: 0.7447\n",
      "Seed 4, Fold 1, Epoch 3, Pre-training loss: 13.0240, Sparse rate: 0.7446\n",
      "Seed 4, Fold 1, Epoch 4, Pre-training loss: 12.9227, Sparse rate: 0.7443\n",
      "Seed 4, Fold 1, Epoch 5, Pre-training loss: 12.8520, Sparse rate: 0.7443\n",
      "Seed 4, Fold 1, Epoch 6, Pre-training loss: 12.7698, Sparse rate: 0.7443\n",
      "Seed 4, Fold 1, Epoch 7, Pre-training loss: 12.7223, Sparse rate: 0.7441\n",
      "Seed 4, Fold 1, Epoch 8, Pre-training loss: 12.6815, Sparse rate: 0.7440\n",
      "Seed 4, Fold 1, Epoch 9, Pre-training loss: 12.6416, Sparse rate: 0.7435\n",
      "Seed 4, Fold 1, Epoch 10, Pre-training loss: 12.6124, Sparse rate: 0.7432\n",
      "Seed 4, Fold 1, Epoch 20, Train loss: 0.6878, Val acc: 0.6087\n",
      "Seed 4, Fold 1, Epoch 30, Train loss: 0.6863, Val acc: 0.6087\n",
      "Seed 4, Fold 1, Epoch 40, Train loss: 0.6859, Val acc: 0.6087\n",
      "Seed 4, Fold 1, Epoch 50, Train loss: 0.6799, Val acc: 0.6087\n",
      "Seed 4, Fold 1, Epoch 60, Train loss: 0.6796, Val acc: 0.6087\n",
      "Seed 4, Fold 1, Test acc: 0.6279, AUC: 0.5000, Sensitivity: 0.0000, Specificity: 1.0000\n",
      "Seed 4, Fold 2, Epoch 1, Pre-training loss: 12.9812, Sparse rate: 0.7527\n",
      "Seed 4, Fold 2, Epoch 2, Pre-training loss: 12.8961, Sparse rate: 0.7527\n",
      "Seed 4, Fold 2, Epoch 3, Pre-training loss: 12.8105, Sparse rate: 0.7527\n",
      "Seed 4, Fold 2, Epoch 4, Pre-training loss: 12.7420, Sparse rate: 0.7526\n",
      "Seed 4, Fold 2, Epoch 5, Pre-training loss: 12.7021, Sparse rate: 0.7525\n",
      "Seed 4, Fold 2, Epoch 6, Pre-training loss: 12.6633, Sparse rate: 0.7519\n",
      "Seed 4, Fold 2, Epoch 7, Pre-training loss: 12.6270, Sparse rate: 0.7515\n",
      "Seed 4, Fold 2, Epoch 8, Pre-training loss: 12.5944, Sparse rate: 0.7513\n",
      "Seed 4, Fold 2, Epoch 9, Pre-training loss: 12.5592, Sparse rate: 0.7507\n",
      "Seed 4, Fold 2, Epoch 10, Pre-training loss: 12.5237, Sparse rate: 0.7503\n",
      "Seed 4, Fold 2, Epoch 20, Train loss: 0.6869, Val acc: 0.6377\n",
      "Seed 4, Fold 2, Epoch 30, Train loss: 0.6815, Val acc: 0.6377\n",
      "Seed 4, Fold 2, Epoch 40, Train loss: 0.6834, Val acc: 0.6377\n",
      "Seed 4, Fold 2, Epoch 50, Train loss: 0.6780, Val acc: 0.6377\n",
      "Seed 4, Fold 2, Epoch 60, Train loss: 0.6755, Val acc: 0.6377\n",
      "Seed 4, Fold 2, Test acc: 0.5233, AUC: 0.5000, Sensitivity: 0.0000, Specificity: 1.0000\n",
      "Seed 4, Fold 3, Epoch 1, Pre-training loss: 13.0395, Sparse rate: 0.7484\n",
      "Seed 4, Fold 3, Epoch 2, Pre-training loss: 12.9680, Sparse rate: 0.7482\n",
      "Seed 4, Fold 3, Epoch 3, Pre-training loss: 12.8885, Sparse rate: 0.7482\n",
      "Seed 4, Fold 3, Epoch 4, Pre-training loss: 12.8197, Sparse rate: 0.7479\n",
      "Seed 4, Fold 3, Epoch 5, Pre-training loss: 12.7715, Sparse rate: 0.7473\n",
      "Seed 4, Fold 3, Epoch 6, Pre-training loss: 12.7292, Sparse rate: 0.7467\n",
      "Seed 4, Fold 3, Epoch 7, Pre-training loss: 12.6876, Sparse rate: 0.7464\n",
      "Seed 4, Fold 3, Epoch 8, Pre-training loss: 12.6521, Sparse rate: 0.7462\n",
      "Seed 4, Fold 3, Epoch 9, Pre-training loss: 12.6156, Sparse rate: 0.7457\n",
      "Seed 4, Fold 3, Epoch 10, Pre-training loss: 12.5792, Sparse rate: 0.7451\n",
      "Seed 4, Fold 3, Epoch 20, Train loss: 0.6827, Val acc: 0.5942\n",
      "Seed 4, Fold 3, Epoch 30, Train loss: 0.6809, Val acc: 0.5942\n",
      "Seed 4, Fold 3, Epoch 40, Train loss: 0.6871, Val acc: 0.5942\n",
      "Seed 4, Fold 3, Epoch 50, Train loss: 0.6739, Val acc: 0.5942\n",
      "Seed 4, Fold 3, Epoch 60, Train loss: 0.6820, Val acc: 0.5942\n",
      "Seed 4, Fold 3, Test acc: 0.5059, AUC: 0.5000, Sensitivity: 0.0000, Specificity: 1.0000\n",
      "Seed 4, Fold 4, Epoch 1, Pre-training loss: 13.1468, Sparse rate: 0.7484\n",
      "Seed 4, Fold 4, Epoch 2, Pre-training loss: 13.0546, Sparse rate: 0.7483\n",
      "Seed 4, Fold 4, Epoch 3, Pre-training loss: 12.9730, Sparse rate: 0.7483\n",
      "Seed 4, Fold 4, Epoch 4, Pre-training loss: 12.9076, Sparse rate: 0.7480\n",
      "Seed 4, Fold 4, Epoch 5, Pre-training loss: 12.8576, Sparse rate: 0.7478\n",
      "Seed 4, Fold 4, Epoch 6, Pre-training loss: 12.8082, Sparse rate: 0.7477\n",
      "Seed 4, Fold 4, Epoch 7, Pre-training loss: 12.7699, Sparse rate: 0.7477\n",
      "Seed 4, Fold 4, Epoch 8, Pre-training loss: 12.7285, Sparse rate: 0.7473\n",
      "Seed 4, Fold 4, Epoch 9, Pre-training loss: 12.6944, Sparse rate: 0.7470\n",
      "Seed 4, Fold 4, Epoch 10, Pre-training loss: 12.6581, Sparse rate: 0.7470\n",
      "Seed 4, Fold 4, Epoch 20, Train loss: 0.6817, Val acc: 0.5652\n",
      "Seed 4, Fold 4, Epoch 30, Train loss: 0.6827, Val acc: 0.5652\n",
      "Seed 4, Fold 4, Epoch 40, Train loss: 0.6856, Val acc: 0.5652\n",
      "Seed 4, Fold 4, Epoch 50, Train loss: 0.6857, Val acc: 0.5652\n",
      "Seed 4, Fold 4, Epoch 60, Train loss: 0.6792, Val acc: 0.5652\n",
      "Seed 4, Fold 4, Test acc: 0.6000, AUC: 0.5000, Sensitivity: 0.0000, Specificity: 1.0000\n",
      "Seed 4, Fold 5, Epoch 1, Pre-training loss: 13.3148, Sparse rate: 0.7533\n",
      "Seed 4, Fold 5, Epoch 2, Pre-training loss: 13.2073, Sparse rate: 0.7530\n",
      "Seed 4, Fold 5, Epoch 3, Pre-training loss: 13.0671, Sparse rate: 0.7528\n",
      "Seed 4, Fold 5, Epoch 4, Pre-training loss: 12.9451, Sparse rate: 0.7528\n",
      "Seed 4, Fold 5, Epoch 5, Pre-training loss: 12.8477, Sparse rate: 0.7527\n",
      "Seed 4, Fold 5, Epoch 6, Pre-training loss: 12.7843, Sparse rate: 0.7524\n",
      "Seed 4, Fold 5, Epoch 7, Pre-training loss: 12.7258, Sparse rate: 0.7522\n",
      "Seed 4, Fold 5, Epoch 8, Pre-training loss: 12.6827, Sparse rate: 0.7515\n",
      "Seed 4, Fold 5, Epoch 9, Pre-training loss: 12.6491, Sparse rate: 0.7513\n",
      "Seed 4, Fold 5, Epoch 10, Pre-training loss: 12.6137, Sparse rate: 0.7507\n",
      "Seed 4, Fold 5, Epoch 20, Train loss: 0.6910, Val acc: 0.5797\n",
      "Seed 4, Fold 5, Epoch 30, Train loss: 0.6912, Val acc: 0.5797\n",
      "Seed 4, Fold 5, Epoch 40, Train loss: 0.6859, Val acc: 0.5797\n",
      "Seed 4, Fold 5, Epoch 50, Train loss: 0.6862, Val acc: 0.5797\n",
      "Seed 4, Fold 5, Epoch 60, Train loss: 0.6881, Val acc: 0.5797\n",
      "Seed 4, Fold 5, Test acc: 0.6235, AUC: 0.5000, Sensitivity: 0.0000, Specificity: 1.0000\n",
      "Final ACC: 0.5781\n",
      "Final AUC: 0.5008\n",
      "Final Sensitivity: 0.0040\n",
      "Final Specificity: 0.9976\n"
     ]
    }
   ],
   "source": [
    "for ind in range(5):\n",
    "    setup_seed(ind)\n",
    "    kf = KFold(n_splits=n_split, shuffle=True)\n",
    "    kfold_index = 0\n",
    "    for trainval_index, test_index in kf.split(X, Y):\n",
    "        kfold_index += 1\n",
    "        X_trainval, X_test = X[trainval_index], X[test_index]\n",
    "        Y_trainval, Y_test = Y[trainval_index], Y[test_index]\n",
    "        kf_inner = KFold(n_splits=n_split, shuffle=True)\n",
    "        train_index, val_index = next(kf_inner.split(X_trainval, Y_trainval))\n",
    "        X_train, X_val = X_trainval[train_index], X_trainval[val_index]\n",
    "        Y_train, Y_val = Y_trainval[train_index], Y_trainval[val_index]\n",
    "\n",
    "        model = Model(dropout=dropout, num_class=2)\n",
    "        model.to(device)\n",
    "        optimizer1 = optim.SGD(model.parameters(), lr=lr/5, weight_decay=decay, momentum=0.9, nesterov=True)\n",
    "        optimizer2 = optim.SGD(model.parameters(), lr=lr, weight_decay=decay, momentum=0.9, nesterov=True)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        best_val_acc = 0\n",
    "        best_model_path = f'outputs/model_seed{ind}_fold{kfold_index}.pth'\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            model.train()\n",
    "            idx_batch = np.random.permutation(int(X_train.shape[0]))\n",
    "            num_batch = X_train.shape[0] // batch_size\n",
    "            pre_num_batch = X_train.shape[0] // pre_batch\n",
    "            loss_train = 0.0\n",
    "\n",
    "            if epoch <= pre_epo:\n",
    "                for bn in range(pre_num_batch):\n",
    "                    batch = idx_batch[bn * pre_batch: (bn + 1) * pre_batch] if bn < pre_num_batch - 1 else idx_batch[bn * pre_batch:]\n",
    "                    train_data_batch = X_train[batch]\n",
    "                    train_data_batch_dev = torch.from_numpy(train_data_batch).float().to(device)\n",
    "                    semi_loss = model(train_data_batch_dev, pre=True)\n",
    "                    loss = sum(semi_loss)\n",
    "                    optimizer1.zero_grad()\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                    optimizer1.step()\n",
    "                    loss_train += loss.item()\n",
    "                loss_train /= pre_num_batch\n",
    "                print(f'Seed {ind}, Fold {kfold_index}, Epoch {epoch}, Pre-training loss: {loss_train:.4f}, Sparse rate: {(model.sigcnn.get_w_data() != 0).int().sum() / (116*116):.4f}')\n",
    "            else:\n",
    "                mini_net = nn.Sequential(model.sigcnn)\n",
    "                for bn in range(num_batch):\n",
    "                    batch = idx_batch[bn * batch_size: (bn + 1) * batch_size] if bn < num_batch - 1 else idx_batch[bn * batch_size:]\n",
    "                    train_data_batch = X_train[batch]\n",
    "                    train_label_batch = Y_train[batch]\n",
    "                    train_data_batch_dev = torch.from_numpy(train_data_batch).float().to(device)\n",
    "                    train_label_batch_dev = torch.from_numpy(train_label_batch).long().to(device)\n",
    "                    model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        train_data_batch_dev, _ = mini_net(train_data_batch_dev)\n",
    "                    model.train()\n",
    "                    outputs = model(train_data_batch_dev)\n",
    "                    loss = loss_fn(outputs, train_label_batch_dev)\n",
    "                    optimizer2.zero_grad()\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                    optimizer2.step()\n",
    "                    loss_train += loss.item()\n",
    "                loss_train /= num_batch\n",
    "\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    val_data_dev = torch.from_numpy(X_val).float().to(device)\n",
    "                    val_label_dev = torch.from_numpy(Y_val).long().to(device)\n",
    "                    val_data_dev, _ = mini_net(val_data_dev)\n",
    "                    outputs = model(val_data_dev)\n",
    "                    _, preds = torch.max(outputs, dim=1)\n",
    "                    val_acc = metrics.accuracy_score(preds.cpu(), Y_val)\n",
    "                    if val_acc > best_val_acc:\n",
    "                        best_val_acc = val_acc\n",
    "                        torch.save(model.state_dict(), best_model_path)\n",
    "                if epoch % 10 == 0:\n",
    "                    print(f'Seed {ind}, Fold {kfold_index}, Epoch {epoch}, Train loss: {loss_train:.4f}, Val acc: {val_acc:.4f}')\n",
    "\n",
    "        model.load_state_dict(torch.load(best_model_path))\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_data_dev = torch.from_numpy(X_test).float().to(device)\n",
    "            test_data_dev, _ = mini_net(test_data_dev)\n",
    "            outputs = model(test_data_dev)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            acc, sen, spec, auc = confusion(Y_test, preds.cpu().numpy())\n",
    "            print(f'Seed {ind}, Fold {kfold_index}, Test acc: {acc:.4f}, AUC: {auc:.4f}, Sensitivity: {sen:.4f}, Specificity: {spec:.4f}')\n",
    "            result.append(acc)\n",
    "            result_auc.append(auc)\n",
    "            result_sen.append(sen)\n",
    "            result_spec.append(spec)\n",
    "\n",
    "# Final results\n",
    "print(f'Final ACC: {np.mean(result):.4f}')\n",
    "print(f'Final AUC: {np.mean(result_auc):.4f}')\n",
    "print(f'Final Sensitivity: {np.mean(result_sen):.4f}')\n",
    "print(f'Final Specificity: {np.mean(result_spec):.4f}')\n",
    "np.save('outputs/results.npy', result)\n",
    "np.save('outputs/aucs.npy', result_auc)\n",
    "np.save('outputs/sens.npy', result_sen)\n",
    "np.save('outputs/specs.npy', result_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
