问题1

```
root@autodl-container-058b4a9bf2-0d2784b7:~/autodl-tmp/brain_generation# python main.py
Traceback (most recent call last):
  File "/root/autodl-tmp/brain_generation/main.py", line 7, in <module>
    import hydra
ModuleNotFoundError: No module named 'hydra'
root@autodl-container-058b4a9bf2-0d2784b7:~/autodl-tmp/brain_generation# pip install hydra-core

```

问题2
发现每个问题都要解决导包报错，于是

```
root@autodl-container-058b4a9bf2-0d2784b7:~/autodl-tmp/brain_generation# conda env create -f environment.yaml
```

现在能运行几个training，但是整体还是跑不了

我发现师兄给的扩散模型代码，用的[这个包](https://github.com/AndreasBergmeister/graph-generation)
原文：Bergmeister 等 - 2024 - EFFICIENT AND SCALABLE GRAPH GENERATION THROUGH ITERATIVE LOCAL EXPANSION_zh-CN_dual.pdf

IDEA：考虑用这个扩散模型的思想，然后用brainUSL的代码结构？

OK接下来要做的是学习论文里扩散模型的思想，

问题3
```
文件 "/root/autodl-tmp/brain_generation/graph_generation/model/ppgn.py", 第 79 行, 在 forward 中 断言 th.allclose(x, x.transpose(1, 2)), "假设 x 是对称矩阵"
```
graph_generation/model/ppgn.py 第 79 行，PPGN 模型的 forward 函数要求输入张量 x（邻接矩阵）是对称的，即 x[i, j] == x[j, i]。

修改 adj_to_binary_graph_networkx 函数，确保生成的 NetworkX 图是无向图，并且邻接矩阵在转换回 np.ndarray 时保持对称性：
```python
def adj_to_binary_graph_networkx(adj_matrix, threshold=0.6):
    """
    Convert adjacency matrix to a binary NetworkX graph where edges are
    set to 1 if their absolute value is greater than the threshold.

    Args:
        adj_matrix (np.ndarray): Adjacency matrix (can be weighted).
        threshold (float): Threshold for binarizing the adjacency matrix.

    Returns:
        list: List of binary NetworkX graphs.
    """
    graphs = []
    for idx, sample in enumerate(adj_matrix):
        G_nx = nx.Graph()  # 无向图，确保对称性
        num_nodes = sample.shape[0]
        if sample.shape[0] != sample.shape[1]:
            raise ValueError(f"Adjacency matrix at index {idx} is not square: shape {sample.shape}")
        G_nx.add_nodes_from(range(num_nodes))

        # 遍历上三角并确保对称性
        for i in range(num_nodes):
            for j in range(i + 1, num_nodes):
                weight = (sample[i, j] + sample[j, i]) / 2  # 平均权重以确保对称
                if abs(weight) >= threshold:
                    G_nx.add_edge(i, j, weight=1)  # 无向图会自动添加 (j, i)

        graphs.append(G_nx)
    return graphs
```

- **改动**：
    - 使用 (sample[i, j] + sample[j, i]) / 2 平均权重，确保生成的边权重对称。
    - nx.Graph() 是无向图，自动保证 (i, j) 和 (j, i) 一致。
- **效果**：生成的 NetworkX 图是无向图，转换为邻接矩阵时（通过 nx.to_numpy_array）将保持对称性。

问题4
日志中的警告表明 train_graphs 的权重超出 [-1, 1] 范围（max=1.804）。这可能导致模型训练不稳定，尤其是在扩散模型中。以下是处理方法：

在 load_fold_data 中归一化权重

在 \_validate_fold_data 中添加归一化步骤，将权重缩放到 [-1, 1]

2025.07.13……上面一系列操作结果整了一个
python main.py
无响应直接退出

---
20250714换思路
跑少批次main文件做demo
```config.yaml
defaults:
  - _self_
  - dataset: planar
  - diffusion: discrete

diffusion:
  self_conditioning: False
  num_steps: 100  # 减少扩散步数，加快推理

training:
  batch_size: 4   # 减小批大小，降低内存需求
  lr: 1e-4        # 略微提高学习率，加速收敛
  num_steps: 1000 # 有限步数，适合快速 demo
  max_num_workers: 4  # 减少工作线程，降低 CPU 负载
  log_interval: 100
  save_ff: True
  resume: False
  kf_flod_index: 4  # 保持使用第 4 折数据

validation:
  batch_size: null
  interval: 500     # 缩短验证间隔，快速查看结果
  first_step: 500   # 第一次验证提前
  per_graph_size: False

testing: False  # 保持训练模式

model:
  name: ppgn
  emb_features: 16   # 减小嵌入特征维度
  hidden_features: 128  # 减小隐藏特征维度
  ppgn_features: 64  # 减小 PPGN 特征维度
  num_layers: 4      # 减少层数，降低计算量
  dropout: 0.1

ema:
  betas: [0.999]
  gamma: 1
  power: 0.67

name: demo
debugging: False

wandb:
  logging: False
```

修改config之后
```cmd
File "/root/autodl-tmp/brain1/graph_generation/training.py", line 183, in train if self.cfg.training.save_checkpoint: omegaconf.errors.ConfigAttributeError: Key 'save_checkpoint' is not in struct full_key: training.save_checkpoint object_type=dict
```
cfg.training.save_checkpoint 在配置文件 config.yaml 中未定义，而代码尝试访问这个键

1. 验证加载配置
```
python main.py --cfg job
```
2. 验证配置详情
```
python main.py --info
```

打开 graph_generation/training.py，找到第 183 行附近的代码修改为以下代码，即可跳过检查点错误
```
                # if self.cfg.training.save_checkpoint:
                if getattr(self.cfg.training, "save_checkpoint", False):
```

接下来运行demo
```
(graph-generation) root@autodl-container-2f064db505-46c7301f:~/autodl-tmp/brain1# python main.py
Total number of model parameters: 0.392866 Million
Training model on cuda:0
training:
   loss: 0.17592917382717133
   step_time: 0.04691934585571289
training:
   loss: 0.1433027982711792
   step_time: 0.04724931716918945
training:
   loss: 0.09998659789562225
   step_time: 0.03543877601623535
training:
   loss: 0.13174784183502197
   step_time: 0.05118060111999512
training:
   loss: 0.12121835350990295
   step_time: 0.03648233413696289
Running validation at 500 steps.
/root/miniconda3/envs/graph-generation/lib/python3.10/site-packages/powerlaw.py:699: RuntimeWarning: invalid value encountered in divide
  (CDF_diff**2) /

```

- 错误类型：RuntimeWarning: invalid value encountered in divide
- 错误位置：/root/miniconda3/envs/graph-generation/lib/python3.10/site-packages/powerlaw.py, 第 699 行
- 错误原因
**powerlaw 警告**：powerlaw.py:699 的 RuntimeWarning: invalid value encountered in divide 通常表示除法操作中分母为零或结果为 NaN，可能由以下原因引起：

1. **度分布异常**：验证图（val_graphs_4.pkl）的度分布不适合幂律拟合，例如：
    - 图为空（无节点或边）。
    - 所有节点度数相同（方差为零）。
    - 包含孤立节点或度数为零的节点。
2. **其他指标调用 powerlaw**：除了 NodeDegree，OrbitCount, Spectral, 或 Wavelet 等指标可能也尝试拟合幂律分布，导致类似问题。
3. **生成图质量**：500 步训练可能不足以生成高质量图，导致验证时的图结构异常（例如稀疏或断连），触发 powerlaw 错误。
