扩散模型是一种生成模型，常用与于图像生成

## 1. 扩散模型的基本思想

扩散模型的核心在于模拟数据的“扩散”和“恢复”过程：

- **前向过程（加噪）**：从真实数据开始，逐步添加噪声，最终将数据变成纯噪声。
- **反向过程（去噪）**：从纯噪声开始，逐步去除噪声，恢复到接近真实数据的样本。

这个过程可以看作是一个“破坏”与“重建”的循环，其中前向过程是固定的，而反向过程需要通过神经网络学习。

## 2. 前向过程（加噪）

前向过程是一个固定的、不可学习的扩散过程，通常被建模为一个马尔科夫链。目标是将真实数据逐步“污染”成纯噪声。

- **时间步**：将扩散过程离散化为 T 个时间步，从 t=0（原始数据）到 t=T（纯噪声）。
- **噪声调度**：噪声的强度由一个预定义的调度函数  $\beta_t$ ​ 控制， $\beta_t$ ​ 决定了每个时间步添加的噪声量，通常  0 < $\beta_t$ < 1 。

- **数学表示**：  $\mathbf{x}_t = \sqrt{1 - \beta_t} \mathbf{x}_{t-1} + \sqrt{\beta_t} \boldsymbol{\epsilon}_t$， 其中，$\boldsymbol{\epsilon}_t \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$ 是标准高斯噪声，$\mathbf{I}$ 是单位矩阵。
- **累积效应**：经过足够多的时间步（即 $T$ 很大时），$\mathbf{x}_T$ 会趋近于纯高斯噪声 $\mathcal{N}(\mathbf{0}, \mathbf{I})$


## 3. 反向过程（去噪）

反向过程的目标是从纯噪声$\mathbf{x}_T$ 开始，逐步恢复到原始数据 $\mathbf{x}_0$。这个过程无法直接计算，因此需要通过神经网络学习。具体如下：
- **目标**：学习从 $\mathbf{x}_t$ 到 $\mathbf{x}_{t-1}$ 的逆向概率分布 $p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_t)$。
- **关键点**：由于直接建模 $\mathbf{x}_{t-1}$ 较复杂，实际训练中通常让神经网络$\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)$预测在 $\mathbf{x}_t$ 中添加的噪声 $\boldsymbol{\epsilon}_t$。

- **损失函数**：用均方误差（MSE）:$\mathcal{L}(\theta) = \mathbb{E}_{t, \mathbf{x}_0, \boldsymbol{\epsilon}} \left[ \left| \boldsymbol{\epsilon} - \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) \right|^2 \right]$  
  其中，期望 $\mathbb{E}$ 是对时间步 $t$、数据 $\mathbf{x}_0$ 和噪声 $\boldsymbol{\epsilon}$ 的平均。
- **优化**：通过梯度下降优化神经网络参数 $\theta$，使损失函数最小化。
  
## 6. 关键点

- 噪声调度（Noise Schedule）：$\beta_t$ 的选择对模型性能至关重要。常见的调度包括：线性调度，随时间线性增加），和余弦调度（平滑过渡）。

[zotero://select/library/items/SIRAHEA3](zotero://select/library/items/SIRAHEA3)